{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6XB2Qxl74jdF",
        "outputId": "bd6cfd65-c6b5-49a6-f266-df28fd272526"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/francismon/curated-colon-dataset-for-deep-learning?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.41G/1.41G [00:14<00:00, 104MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded to: /root/.cache/kagglehub/datasets/francismon/curated-colon-dataset-for-deep-learning/versions/1\n",
            "Directory: /content/colon_dataset\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "import shutil\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "# Download the dataset\n",
        "dataset_path = kagglehub.dataset_download(\"francismon/curated-colon-dataset-for-deep-learning\")\n",
        "print(\"Downloaded to:\", dataset_path)\n",
        "\n",
        "# Manually copy from kagglehub directory to /content\n",
        "source_dir = dataset_path\n",
        "target_dir = \"/content/colon_dataset\"\n",
        "\n",
        "# Recursively copy the directory to /content\n",
        "shutil.copytree(source_dir, target_dir, dirs_exist_ok=True)\n",
        "\n",
        "# List contents of the copied folder\n",
        "for root, dirs, files in os.walk(target_dir):\n",
        "    print(f\"Directory: {root}\")\n",
        "    for f in files:\n",
        "        print(f\" - {f}\")\n",
        "    break  # Just show the top-level\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# List all files and directories inside the dataset\n",
        "for root, dirs, files in os.walk(\"/content/colon_dataset\"):\n",
        "    print(f\"Directory: {root}\")\n",
        "    for dir_name in dirs:\n",
        "        print(f\"  └── {dir_name}\")\n",
        "    break  # only show the top-level structure\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zjbb3id45gA9",
        "outputId": "58042681-3925-4665-8304-5b5280e385d1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory: /content/colon_dataset\n",
            "  └── test\n",
            "  └── train\n",
            "  └── val\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# List all files and directories inside the dataset\n",
        "for root, dirs, files in os.walk(\"/content/colon_dataset/val\"):\n",
        "    print(f\"Directory: {root}\")\n",
        "    for dir_name in dirs:\n",
        "        print(f\"  └── {dir_name}\")\n",
        "    break  # only show the top-level structure\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nAjg6k905nQe",
        "outputId": "dcda0314-cb37-4340-a2fb-1a46eb334bfd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory: /content/colon_dataset/val\n",
            "  └── 3_esophagitis\n",
            "  └── 1_ulcerative_colitis\n",
            "  └── 2_polyps\n",
            "  └── 0_normal\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score, f1_score, precision_score, recall_score, average_precision_score\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import DenseNet121\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import seaborn as sns\n"
      ],
      "metadata": {
        "id": "u5h55YZU6L5h"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "\n",
        "# Base original data directory\n",
        "base_dir = \"/content/colon_dataset\"\n",
        "train_dir = os.path.join(base_dir, \"train\")\n",
        "val_dir = os.path.join(base_dir, \"val\")\n",
        "test_dir = os.path.join(base_dir, \"test\")\n",
        "\n",
        "# New root for fixed structure\n",
        "fixed_base_dir = \"/content/colon_data_fixed\"\n",
        "combined_dir = os.path.join(fixed_base_dir, \"all_data\")\n",
        "new_train_dir = os.path.join(fixed_base_dir, \"train\")\n",
        "new_test_dir = os.path.join(fixed_base_dir, \"test\")\n",
        "new_val_dir = os.path.join(fixed_base_dir, \"val\")\n",
        "\n",
        "# Create fixed base directory\n",
        "os.makedirs(combined_dir, exist_ok=True)\n",
        "\n",
        "# Combine train + test data into one \"all_data\" folder\n",
        "for source_folder in [train_dir, test_dir]:\n",
        "    for class_name in os.listdir(source_folder):\n",
        "        src_path = os.path.join(source_folder, class_name)\n",
        "        dst_path = os.path.join(combined_dir, class_name)\n",
        "        os.makedirs(dst_path, exist_ok=True)\n",
        "        for file in os.listdir(src_path):\n",
        "            shutil.copy(os.path.join(src_path, file), os.path.join(dst_path, file))\n",
        "\n",
        "# Function to split into 80% train / 20% test\n",
        "def split_data(source_dir, train_dir, test_dir, ratio=0.8):\n",
        "    for class_name in os.listdir(source_dir):\n",
        "        class_path = os.path.join(source_dir, class_name)\n",
        "        files = os.listdir(class_path)\n",
        "        random.shuffle(files)\n",
        "        split_idx = int(len(files) * ratio)\n",
        "\n",
        "        train_files = files[:split_idx]\n",
        "        test_files = files[split_idx:]\n",
        "\n",
        "        for out_dir, file_list in [(train_dir, train_files), (test_dir, test_files)]:\n",
        "            class_out = os.path.join(out_dir, class_name)\n",
        "            os.makedirs(class_out, exist_ok=True)\n",
        "            for f in file_list:\n",
        "                shutil.copy(os.path.join(class_path, f), os.path.join(class_out, f))\n",
        "\n",
        "# Apply the split\n",
        "split_data(combined_dir, new_train_dir, new_test_dir)\n",
        "\n",
        "# Copy val data unchanged\n",
        "shutil.copytree(val_dir, new_val_dir, dirs_exist_ok=True)\n",
        "\n",
        "print(\"✅ Split complete!\")\n",
        "print(\"Train path:\", new_train_dir)\n",
        "print(\"Test path:\", new_test_dir)\n",
        "print(\"Validation path:\", new_val_dir)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mKYWQu4E6i2r",
        "outputId": "088d47fc-788a-4e48-ea9f-14a1b7df0da8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Split complete!\n",
            "Train path: /content/colon_data_fixed/train\n",
            "Test path: /content/colon_data_fixed/test\n",
            "Validation path: /content/colon_data_fixed/val\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Original train folder\n",
        "original_train_dir = '/content/colon_dataset/train'\n",
        "train_split_dir = '/content/colon_dataset/train_split'\n",
        "test_split_dir = '/content/colon_dataset/test_split'\n",
        "\n",
        "# Make new directories\n",
        "os.makedirs(train_split_dir, exist_ok=True)\n",
        "os.makedirs(test_split_dir, exist_ok=True)\n",
        "\n",
        "for class_name in os.listdir(original_train_dir):\n",
        "    class_dir = os.path.join(original_train_dir, class_name)\n",
        "    if os.path.isdir(class_dir):\n",
        "        images = os.listdir(class_dir)\n",
        "        train_imgs, test_imgs = train_test_split(images, test_size=0.2, random_state=42)\n",
        "\n",
        "        os.makedirs(os.path.join(train_split_dir, class_name), exist_ok=True)\n",
        "        os.makedirs(os.path.join(test_split_dir, class_name), exist_ok=True)\n",
        "\n",
        "        # Move images\n",
        "        for img in train_imgs:\n",
        "            shutil.copy2(os.path.join(class_dir, img), os.path.join(train_split_dir, class_name, img))\n",
        "        for img in test_imgs:\n",
        "            shutil.copy2(os.path.join(class_dir, img), os.path.join(test_split_dir, class_name, img))\n",
        "\n",
        "print(\"✅ Train/Test split (80/20) completed.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nV-a74Ce7Zm9",
        "outputId": "8afd7926-b2a3-439e-c329-26880e3f7710"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Train/Test split (80/20) completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = '/content/colon_dataset/train_split'\n",
        "test_dir = '/content/colon_dataset/test_split'\n",
        "val_dir = '/content/colon_dataset/val'\n",
        "\n",
        "# [Keep the rest of the code unchanged]\n"
      ],
      "metadata": {
        "id": "9jPOA4C579bd"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "\n",
        "img_size = (224, 224)\n",
        "batch_size = 32\n",
        "\n",
        "train_dir = '/content/colon_dataset/train_split'\n",
        "test_dir = '/content/colon_dataset/test_split'\n",
        "val_dir = '/content/colon_dataset/val'\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1stemUW8EIF",
        "outputId": "1b5696d6-6926-400d-c80f-d3ce576b74e7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2560 images belonging to 4 classes.\n",
            "Found 2000 images belonging to 4 classes.\n",
            "Found 640 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "img_size = (224, 224)\n",
        "batch_size = 32\n",
        "\n",
        "# Training and augmentation\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    '/content/colon_dataset/train_split',\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    '/content/colon_dataset/test_split',\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    '/content/colon_dataset/val',\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3jbWpQs8XF-",
        "outputId": "236de5e6-f28a-4e5f-fecf-72605865c265"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2560 images belonging to 4 classes.\n",
            "Found 640 images belonging to 4 classes.\n",
            "Found 2000 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import DenseNet121\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dropout(0.5)(x)\n",
        "predictions = Dense(4, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Freeze base model\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46cjYkoe8bm5",
        "outputId": "c9c9fa89-261c-46e7-f663-7dfcc6a997a3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m29084464/29084464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=10,\n",
        "    validation_data=val_generator\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w8Lv_w_q8fve",
        "outputId": "34ec75bc-4e90-4d2e-a9c2-ce915d98e765"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 762ms/step - accuracy: 0.2643 - loss: 2.0035 - val_accuracy: 0.4400 - val_loss: 1.2484\n",
            "Epoch 2/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 431ms/step - accuracy: 0.3801 - loss: 1.5998 - val_accuracy: 0.5835 - val_loss: 1.0564\n",
            "Epoch 3/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 422ms/step - accuracy: 0.4855 - loss: 1.3047 - val_accuracy: 0.6625 - val_loss: 0.9043\n",
            "Epoch 4/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 434ms/step - accuracy: 0.5355 - loss: 1.1251 - val_accuracy: 0.6825 - val_loss: 0.8161\n",
            "Epoch 5/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 430ms/step - accuracy: 0.5999 - loss: 0.9937 - val_accuracy: 0.7350 - val_loss: 0.7277\n",
            "Epoch 6/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 429ms/step - accuracy: 0.6423 - loss: 0.8761 - val_accuracy: 0.7540 - val_loss: 0.6782\n",
            "Epoch 7/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 439ms/step - accuracy: 0.6617 - loss: 0.8161 - val_accuracy: 0.7875 - val_loss: 0.6158\n",
            "Epoch 8/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 430ms/step - accuracy: 0.6982 - loss: 0.7502 - val_accuracy: 0.7905 - val_loss: 0.5961\n",
            "Epoch 9/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 485ms/step - accuracy: 0.7728 - loss: 0.5851 - val_accuracy: 0.8255 - val_loss: 0.5392\n",
            "Epoch 10/10\n",
            "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 489ms/step - accuracy: 0.7668 - loss: 0.6115 - val_accuracy: 0.8355 - val_loss: 0.5142\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, average_precision_score, f1_score, precision_score, recall_score\n",
        "import numpy as np\n",
        "\n",
        "# Predict on test set\n",
        "y_true = test_generator.classes\n",
        "y_pred_probs = model.predict(test_generator)\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "# Basic metrics\n",
        "accuracy = np.mean(y_true == y_pred)\n",
        "f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "precision = precision_score(y_true, y_pred, average='weighted')\n",
        "recall = recall_score(y_true, y_pred, average='weighted')\n",
        "roc_auc = roc_auc_score(y_true, y_pred_probs, multi_class='ovr')\n",
        "aupr = average_precision_score(y_true, y_pred_probs, average='weighted')\n",
        "conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "report = classification_report(y_true, y_pred)\n",
        "\n",
        "# Print results\n",
        "print(f\"✅ Accuracy: {accuracy:.4f}\")\n",
        "print(f\"✅ ROC AUC Score: {roc_auc:.4f}\")\n",
        "print(f\"✅ AUPR Score: {aupr:.4f}\")\n",
        "print(f\"✅ Precision: {precision:.4f}\")\n",
        "print(f\"✅ Recall: {recall:.4f}\")\n",
        "print(f\"✅ F1 Score: {f1:.4f}\")\n",
        "print(f\"\\n✅ Confusion Matrix:\\n{conf_matrix}\")\n",
        "print(f\"\\n✅ Classification Report:\\n{report}\")\n"
      ],
      "metadata": {
        "id": "3hoCtM6I8lYC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2844357f-f1de-4123-b8df-5a6e1b2d0b19"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 214ms/step\n",
            "✅ Accuracy: 0.9328\n",
            "✅ ROC AUC Score: 0.9919\n",
            "✅ AUPR Score: 0.9792\n",
            "✅ Precision: 0.9326\n",
            "✅ Recall: 0.9328\n",
            "✅ F1 Score: 0.9323\n",
            "\n",
            "✅ Confusion Matrix:\n",
            "[[157   2   1   0]\n",
            " [  8 140  11   1]\n",
            " [  4  10 143   3]\n",
            " [  1   1   1 157]]\n",
            "\n",
            "✅ Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.98      0.95       160\n",
            "           1       0.92      0.88      0.89       160\n",
            "           2       0.92      0.89      0.91       160\n",
            "           3       0.98      0.98      0.98       160\n",
            "\n",
            "    accuracy                           0.93       640\n",
            "   macro avg       0.93      0.93      0.93       640\n",
            "weighted avg       0.93      0.93      0.93       640\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler, label_binarize\n",
        "from sklearn.metrics import (accuracy_score, roc_auc_score, average_precision_score,\n",
        "                             precision_score, recall_score, f1_score, confusion_matrix,\n",
        "                             classification_report)\n",
        "from tensorflow.keras.applications import DenseNet121\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import GaussianNoise, Dropout\n",
        "from tensorflow.keras.applications.densenet import preprocess_input\n",
        "from tqdm import tqdm\n",
        "\n",
        "# -----------------------------------\n",
        "# 1. Load DenseNet121 with Regularization\n",
        "# -----------------------------------\n",
        "base_model = DenseNet121(weights='imagenet', include_top=False, pooling='avg', input_shape=(224, 224, 3))\n",
        "\n",
        "# Add Gaussian Noise and Dropout for regularization\n",
        "x = GaussianNoise(0.1)(base_model.output)\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "# Final feature extraction model\n",
        "feature_model = Model(inputs=base_model.input, outputs=x)\n",
        "\n",
        "# -----------------------------------\n",
        "# 2. Feature Extraction Function\n",
        "# -----------------------------------\n",
        "def extract_features(generator, model):\n",
        "    features, labels = [], []\n",
        "    for i in tqdm(range(len(generator))):\n",
        "        x_batch, y_batch = generator[i]\n",
        "        x_batch = preprocess_input(x_batch)\n",
        "        batch_features = model.predict(x_batch, verbose=0)\n",
        "        features.append(batch_features)\n",
        "        labels.append(y_batch)\n",
        "    return np.vstack(features), np.concatenate(labels)\n",
        "\n",
        "# -----------------------------------\n",
        "# 3. Extract Features from Train/Val/Test Sets\n",
        "# (Assumes `train_generator`, `val_generator`, and `test_generator` are already defined)\n",
        "# -----------------------------------\n",
        "train_features, train_labels = extract_features(train_generator, feature_model)\n",
        "val_features, val_labels = extract_features(val_generator, feature_model)\n",
        "test_features, test_labels = extract_features(test_generator, feature_model)\n",
        "\n"
      ],
      "metadata": {
        "id": "FN_oMnbIDouN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ac74f1c-8ee8-4dc7-faab-e42e27d3c0b6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 80/80 [00:41<00:00,  1.93it/s]\n",
            "100%|██████████| 63/63 [00:36<00:00,  1.74it/s]\n",
            "100%|██████████| 20/20 [00:08<00:00,  2.36it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components=0.95)  # Keep 95% variance\n",
        "train_features = pca.fit_transform(train_features)\n",
        "val_features = pca.transform(val_features)\n",
        "test_features = pca.transform(test_features)\n"
      ],
      "metadata": {
        "id": "6UctfO5nMAHx"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, roc_auc_score, average_precision_score,\n",
        "    precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
        ")\n",
        "from sklearn.preprocessing import label_binarize\n",
        "import numpy as np\n",
        "\n",
        "# Fix the label shape\n",
        "train_labels = np.argmax(train_labels, axis=1)\n",
        "test_labels = np.argmax(test_labels, axis=1)\n",
        "\n",
        "# Train SVM\n",
        "svm_clf = make_pipeline(StandardScaler(), SVC(kernel='rbf', probability=True, C=10, gamma='scale', random_state=42))\n",
        "svm_clf.fit(train_features, train_labels)\n",
        "\n",
        "# Predict\n",
        "pred_probs = svm_clf.predict_proba(test_features)\n",
        "pred_labels = np.argmax(pred_probs, axis=1)\n",
        "\n",
        "# Binarize for multi-class metrics\n",
        "n_classes = len(np.unique(test_labels))\n",
        "true_binarized = label_binarize(test_labels, classes=list(range(n_classes)))\n",
        "pred_binarized = label_binarize(pred_labels, classes=list(range(n_classes)))\n",
        "\n",
        "# Metrics\n",
        "accuracy = accuracy_score(test_labels, pred_labels)\n",
        "roc_auc = roc_auc_score(true_binarized, pred_probs, average='macro', multi_class='ovr')\n",
        "aupr = average_precision_score(true_binarized, pred_probs, average='macro')\n",
        "precision = precision_score(test_labels, pred_labels, average='macro')\n",
        "recall = recall_score(test_labels, pred_labels, average='macro')\n",
        "f1 = f1_score(test_labels, pred_labels, average='macro')\n",
        "cm = confusion_matrix(test_labels, pred_labels)\n",
        "report = classification_report(test_labels, pred_labels, target_names=test_generator.class_indices.keys())\n",
        "\n",
        "# Output\n",
        "print(f\"✅ Accuracy: {accuracy:.4f}\")\n",
        "print(f\"✅ ROC AUC Score: {roc_auc:.4f}\")\n",
        "print(f\"✅ AUPR Score: {aupr:.4f}\")\n",
        "print(f\"✅ Precision: {precision:.4f}\")\n",
        "print(f\"✅ Recall: {recall:.4f}\")\n",
        "print(f\"✅ F1 Score: {f1:.4f}\")\n",
        "print(\"\\n✅ Confusion Matrix:\")\n",
        "print(cm)\n",
        "print(\"\\n✅ Classification Report:\")\n",
        "print(report)\n"
      ],
      "metadata": {
        "id": "fq4ayaJJ_JyF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef0f038e-9c1c-48ac-cd15-f9f0b7ed0b19"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Accuracy: 0.9219\n",
            "✅ ROC AUC Score: 0.9898\n",
            "✅ AUPR Score: 0.9730\n",
            "✅ Precision: 0.9222\n",
            "✅ Recall: 0.9219\n",
            "✅ F1 Score: 0.9215\n",
            "\n",
            "✅ Confusion Matrix:\n",
            "[[159   1   0   0]\n",
            " [  1 130  25   4]\n",
            " [  0  13 146   1]\n",
            " [  0   5   0 155]]\n",
            "\n",
            "✅ Classification Report:\n",
            "                      precision    recall  f1-score   support\n",
            "\n",
            "            0_normal       0.99      0.99      0.99       160\n",
            "1_ulcerative_colitis       0.87      0.81      0.84       160\n",
            "            2_polyps       0.85      0.91      0.88       160\n",
            "       3_esophagitis       0.97      0.97      0.97       160\n",
            "\n",
            "            accuracy                           0.92       640\n",
            "           macro avg       0.92      0.92      0.92       640\n",
            "        weighted avg       0.92      0.92      0.92       640\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler, label_binarize\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, roc_auc_score, average_precision_score,\n",
        "    precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
        ")\n",
        "import numpy as np\n",
        "\n",
        "# Optional: scale features (important for some classifiers, less so for RF but keeps consistency)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(train_features)\n",
        "X_test_scaled = scaler.transform(test_features)\n",
        "\n",
        "# Train Random Forest\n",
        "rf_clf = RandomForestClassifier(n_estimators=200, max_depth=20, random_state=42, n_jobs=-1)\n",
        "rf_clf.fit(X_train_scaled, train_labels)\n",
        "\n",
        "# Predict\n",
        "pred_probs = rf_clf.predict_proba(X_test_scaled)\n",
        "pred_labels = np.argmax(pred_probs, axis=1)\n",
        "\n",
        "# Binarize for multi-class AUC and AUPR\n",
        "n_classes = len(np.unique(test_labels))\n",
        "true_binarized = label_binarize(test_labels, classes=list(range(n_classes)))\n",
        "pred_binarized = label_binarize(pred_labels, classes=list(range(n_classes)))\n",
        "\n",
        "# Evaluation\n",
        "accuracy = accuracy_score(test_labels, pred_labels)\n",
        "roc_auc = roc_auc_score(true_binarized, pred_probs, average='macro', multi_class='ovr')\n",
        "aupr = average_precision_score(true_binarized, pred_probs, average='macro')\n",
        "precision = precision_score(test_labels, pred_labels, average='macro')\n",
        "recall = recall_score(test_labels, pred_labels, average='macro')\n",
        "f1 = f1_score(test_labels, pred_labels, average='macro')\n",
        "cm = confusion_matrix(test_labels, pred_labels)\n",
        "report = classification_report(test_labels, pred_labels)\n",
        "\n",
        "# Output\n",
        "print(f\"✅ Accuracy: {accuracy:.4f}\")\n",
        "print(f\"✅ ROC AUC Score: {roc_auc:.4f}\")\n",
        "print(f\"✅ AUPR Score: {aupr:.4f}\")\n",
        "print(f\"✅ Precision: {precision:.4f}\")\n",
        "print(f\"✅ Recall: {recall:.4f}\")\n",
        "print(f\"✅ F1 Score: {f1:.4f}\")\n",
        "\n",
        "print(\"\\n✅ Confusion Matrix:\")\n",
        "print(cm)\n",
        "\n",
        "print(\"\\n✅ Classification Report:\")\n",
        "print(report)\n"
      ],
      "metadata": {
        "id": "SaM5-g3uObtW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d3faf0d-d35a-4644-c12b-ea97991633c8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Accuracy: 0.9031\n",
            "✅ ROC AUC Score: 0.9817\n",
            "✅ AUPR Score: 0.9510\n",
            "✅ Precision: 0.9034\n",
            "✅ Recall: 0.9031\n",
            "✅ F1 Score: 0.9031\n",
            "\n",
            "✅ Confusion Matrix:\n",
            "[[155   5   0   0]\n",
            " [  3 128  25   4]\n",
            " [  0  18 141   1]\n",
            " [  1   4   1 154]]\n",
            "\n",
            "✅ Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.97      0.97       160\n",
            "           1       0.83      0.80      0.81       160\n",
            "           2       0.84      0.88      0.86       160\n",
            "           3       0.97      0.96      0.97       160\n",
            "\n",
            "    accuracy                           0.90       640\n",
            "   macro avg       0.90      0.90      0.90       640\n",
            "weighted avg       0.90      0.90      0.90       640\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.preprocessing import StandardScaler, label_binarize\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, roc_auc_score, average_precision_score,\n",
        "    precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
        ")\n",
        "import numpy as np\n",
        "\n",
        "# Scale features (helps even with XGBoost sometimes)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(train_features)\n",
        "X_test_scaled = scaler.transform(test_features)\n",
        "\n",
        "# Initialize XGBoost classifier\n",
        "xgb_clf = XGBClassifier(\n",
        "    n_estimators=200,\n",
        "    max_depth=8,\n",
        "    learning_rate=0.05,\n",
        "    objective='multi:softprob',\n",
        "    num_class=4,\n",
        "    use_label_encoder=False,\n",
        "    eval_metric='mlogloss',\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Train\n",
        "xgb_clf.fit(X_train_scaled, train_labels)\n",
        "\n",
        "# Predict probabilities and labels\n",
        "pred_probs = xgb_clf.predict_proba(X_test_scaled)\n",
        "pred_labels = np.argmax(pred_probs, axis=1)\n",
        "\n",
        "# Binarize for multi-class AUC and AUPR\n",
        "n_classes = len(np.unique(test_labels))\n",
        "true_binarized = label_binarize(test_labels, classes=list(range(n_classes)))\n",
        "pred_binarized = label_binarize(pred_labels, classes=list(range(n_classes)))\n",
        "\n",
        "# Evaluation metrics\n",
        "accuracy = accuracy_score(test_labels, pred_labels)\n",
        "roc_auc = roc_auc_score(true_binarized, pred_probs, average='macro', multi_class='ovr')\n",
        "aupr = average_precision_score(true_binarized, pred_probs, average='macro')\n",
        "precision = precision_score(test_labels, pred_labels, average='macro')\n",
        "recall = recall_score(test_labels, pred_labels, average='macro')\n",
        "f1 = f1_score(test_labels, pred_labels, average='macro')\n",
        "cm = confusion_matrix(test_labels, pred_labels)\n",
        "report = classification_report(test_labels, pred_labels)\n",
        "\n",
        "# Results\n",
        "print(f\"✅ Accuracy: {accuracy:.4f}\")\n",
        "print(f\"✅ ROC AUC Score: {roc_auc:.4f}\")\n",
        "print(f\"✅ AUPR Score: {aupr:.4f}\")\n",
        "print(f\"✅ Precision: {precision:.4f}\")\n",
        "print(f\"✅ Recall: {recall:.4f}\")\n",
        "print(f\"✅ F1 Score: {f1:.4f}\")\n",
        "\n",
        "print(\"\\n✅ Confusion Matrix:\")\n",
        "print(cm)\n",
        "\n",
        "print(\"\\n✅ Classification Report:\")\n",
        "print(report)\n"
      ],
      "metadata": {
        "id": "BtVsXcJ7PK4p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c599b07e-4ba2-4cea-d900-845e6417736b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [16:16:04] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Accuracy: 0.8906\n",
            "✅ ROC AUC Score: 0.9798\n",
            "✅ AUPR Score: 0.9482\n",
            "✅ Precision: 0.8893\n",
            "✅ Recall: 0.8906\n",
            "✅ F1 Score: 0.8892\n",
            "\n",
            "✅ Confusion Matrix:\n",
            "[[158   1   0   1]\n",
            " [  2 119  31   8]\n",
            " [  0  21 137   2]\n",
            " [  1   3   0 156]]\n",
            "\n",
            "✅ Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.98       160\n",
            "           1       0.83      0.74      0.78       160\n",
            "           2       0.82      0.86      0.84       160\n",
            "           3       0.93      0.97      0.95       160\n",
            "\n",
            "    accuracy                           0.89       640\n",
            "   macro avg       0.89      0.89      0.89       640\n",
            "weighted avg       0.89      0.89      0.89       640\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.preprocessing import StandardScaler, label_binarize\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, roc_auc_score, average_precision_score,\n",
        "    precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
        ")\n",
        "import numpy as np\n",
        "\n",
        "# Scale features (very important for SVM)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(train_features)\n",
        "X_test_scaled = scaler.transform(test_features)\n",
        "\n",
        "# Define base models\n",
        "svm_clf = SVC(kernel='rbf', probability=True, C=2, gamma='scale', random_state=42)\n",
        "rf_clf = RandomForestClassifier(n_estimators=150, max_depth=12, random_state=42, n_jobs=-1)\n",
        "xgb_clf = XGBClassifier(\n",
        "    n_estimators=200,\n",
        "    max_depth=8,\n",
        "    learning_rate=0.05,\n",
        "    objective='multi:softprob',\n",
        "    num_class=4,\n",
        "    use_label_encoder=False,\n",
        "    eval_metric='mlogloss',\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Voting Classifier (soft voting based on probabilities)\n",
        "voting_clf = VotingClassifier(\n",
        "    estimators=[('svm', svm_clf), ('rf', rf_clf), ('xgb', xgb_clf)],\n",
        "    voting='soft',  # soft = use predicted probabilities\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Train ensemble\n",
        "voting_clf.fit(X_train_scaled, train_labels)\n",
        "\n",
        "# Predict\n",
        "pred_probs = voting_clf.predict_proba(X_test_scaled)\n",
        "pred_labels = np.argmax(pred_probs, axis=1)\n",
        "\n",
        "# Binarize for AUC/AUPR\n",
        "n_classes = len(np.unique(test_labels))\n",
        "true_binarized = label_binarize(test_labels, classes=list(range(n_classes)))\n",
        "pred_binarized = label_binarize(pred_labels, classes=list(range(n_classes)))\n",
        "\n",
        "# Metrics\n",
        "accuracy = accuracy_score(test_labels, pred_labels)\n",
        "roc_auc = roc_auc_score(true_binarized, pred_probs, average='macro', multi_class='ovr')\n",
        "aupr = average_precision_score(true_binarized, pred_probs, average='macro')\n",
        "precision = precision_score(test_labels, pred_labels, average='macro')\n",
        "recall = recall_score(test_labels, pred_labels, average='macro')\n",
        "f1 = f1_score(test_labels, pred_labels, average='macro')\n",
        "cm = confusion_matrix(test_labels, pred_labels)\n",
        "report = classification_report(test_labels, pred_labels)\n",
        "\n",
        "# Print results\n",
        "print(f\"✅ Accuracy: {accuracy:.4f}\")\n",
        "print(f\"✅ ROC AUC Score: {roc_auc:.4f}\")\n",
        "print(f\"✅ AUPR Score: {aupr:.4f}\")\n",
        "print(f\"✅ Precision: {precision:.4f}\")\n",
        "print(f\"✅ Recall: {recall:.4f}\")\n",
        "print(f\"✅ F1 Score: {f1:.4f}\")\n",
        "\n",
        "print(\"\\n✅ Confusion Matrix:\")\n",
        "print(cm)\n",
        "\n",
        "print(\"\\n✅ Classification Report:\")\n",
        "print(report)\n"
      ],
      "metadata": {
        "id": "DjWppxaePsco",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35ff83f1-d089-4ec8-fc33-44d64e352759"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Accuracy: 0.9219\n",
            "✅ ROC AUC Score: 0.9894\n",
            "✅ AUPR Score: 0.9731\n",
            "✅ Precision: 0.9229\n",
            "✅ Recall: 0.9219\n",
            "✅ F1 Score: 0.9214\n",
            "\n",
            "✅ Confusion Matrix:\n",
            "[[159   1   0   0]\n",
            " [  1 129  26   4]\n",
            " [  0  13 146   1]\n",
            " [  1   1   2 156]]\n",
            "\n",
            "✅ Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       160\n",
            "           1       0.90      0.81      0.85       160\n",
            "           2       0.84      0.91      0.87       160\n",
            "           3       0.97      0.97      0.97       160\n",
            "\n",
            "    accuracy                           0.92       640\n",
            "   macro avg       0.92      0.92      0.92       640\n",
            "weighted avg       0.92      0.92      0.92       640\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler, label_binarize\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, roc_auc_score, average_precision_score,\n",
        "    precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
        ")\n",
        "import numpy as np\n",
        "\n",
        "# Feature scaling (essential for SVM)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(train_features)\n",
        "X_test_scaled = scaler.transform(test_features)\n",
        "\n",
        "\n",
        "# Meta learner\n",
        "meta_learner = LogisticRegression(max_iter=1000, multi_class='multinomial', solver='lbfgs')\n",
        "\n",
        "# Stacking classifier\n",
        "stacking_clf = StackingClassifier(\n",
        "    estimators=[\n",
        "        ('svm', svm_clf),\n",
        "        ('rf', rf_clf),\n",
        "        ('xgb', xgb_clf)\n",
        "    ],\n",
        "    final_estimator=meta_learner,\n",
        "    stack_method='predict_proba',  # Important for multiclass classification\n",
        "    cv=5,\n",
        "    n_jobs=-1,\n",
        "    passthrough=False\n",
        ")\n",
        "\n",
        "# Train ensemble\n",
        "stacking_clf.fit(X_train_scaled, train_labels)\n",
        "\n",
        "# Predict\n",
        "pred_probs = stacking_clf.predict_proba(X_test_scaled)\n",
        "pred_labels = np.argmax(pred_probs, axis=1)\n",
        "\n",
        "# Binarize for multiclass AUC/AUPR\n",
        "n_classes = len(np.unique(test_labels))\n",
        "true_binarized = label_binarize(test_labels, classes=list(range(n_classes)))\n",
        "pred_binarized = label_binarize(pred_labels, classes=list(range(n_classes)))\n",
        "\n",
        "# Evaluation\n",
        "accuracy = accuracy_score(test_labels, pred_labels)\n",
        "roc_auc = roc_auc_score(true_binarized, pred_probs, average='macro', multi_class='ovr')\n",
        "aupr = average_precision_score(true_binarized, pred_probs, average='macro')\n",
        "precision = precision_score(test_labels, pred_labels, average='macro')\n",
        "recall = recall_score(test_labels, pred_labels, average='macro')\n",
        "f1 = f1_score(test_labels, pred_labels, average='macro')\n",
        "cm = confusion_matrix(test_labels, pred_labels)\n",
        "report = classification_report(test_labels, pred_labels)\n",
        "\n",
        "# Print metrics\n",
        "print(f\"✅ Accuracy: {accuracy:.4f}\")\n",
        "print(f\"✅ ROC AUC Score: {roc_auc:.4f}\")\n",
        "print(f\"✅ AUPR Score: {aupr:.4f}\")\n",
        "print(f\"✅ Precision: {precision:.4f}\")\n",
        "print(f\"✅ Recall: {recall:.4f}\")\n",
        "print(f\"✅ F1 Score: {f1:.4f}\")\n",
        "print(\"\\n✅ Confusion Matrix:\")\n",
        "print(cm)\n",
        "print(\"\\n✅ Classification Report:\")\n",
        "print(report)\n"
      ],
      "metadata": {
        "id": "z215zP78RZeQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98df7052-8018-4df3-e37e-4f1efe7cb23f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Accuracy: 0.9297\n",
            "✅ ROC AUC Score: 0.9922\n",
            "✅ AUPR Score: 0.9797\n",
            "✅ Precision: 0.9304\n",
            "✅ Recall: 0.9297\n",
            "✅ F1 Score: 0.9298\n",
            "\n",
            "✅ Confusion Matrix:\n",
            "[[159   1   0   0]\n",
            " [  1 136  21   2]\n",
            " [  0  13 146   1]\n",
            " [  0   4   2 154]]\n",
            "\n",
            "✅ Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       160\n",
            "           1       0.88      0.85      0.87       160\n",
            "           2       0.86      0.91      0.89       160\n",
            "           3       0.98      0.96      0.97       160\n",
            "\n",
            "    accuracy                           0.93       640\n",
            "   macro avg       0.93      0.93      0.93       640\n",
            "weighted avg       0.93      0.93      0.93       640\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y8WBjehe5jTE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "90 10"
      ],
      "metadata": {
        "id": "YKDb5x-c6Wcu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "\n",
        "# Base original data directory\n",
        "base_dir = \"/content/colon_dataset\"\n",
        "train_dir = os.path.join(base_dir, \"train\")\n",
        "val_dir = os.path.join(base_dir, \"val\")\n",
        "test_dir = os.path.join(base_dir, \"test\")\n",
        "\n",
        "# New root for fixed structure\n",
        "fixed_base_dir = \"/content/colon_data_fixed\"\n",
        "combined_dir = os.path.join(fixed_base_dir, \"all_data\")\n",
        "new_train_dir = os.path.join(fixed_base_dir, \"train\")\n",
        "new_test_dir = os.path.join(fixed_base_dir, \"test\")\n",
        "new_val_dir = os.path.join(fixed_base_dir, \"val\")\n",
        "\n",
        "# Create fixed base directory\n",
        "os.makedirs(combined_dir, exist_ok=True)\n",
        "\n",
        "# Combine train + test data into one \"all_data\" folder\n",
        "for source_folder in [train_dir, test_dir]:\n",
        "    for class_name in os.listdir(source_folder):\n",
        "        src_path = os.path.join(source_folder, class_name)\n",
        "        dst_path = os.path.join(combined_dir, class_name)\n",
        "        os.makedirs(dst_path, exist_ok=True)\n",
        "        for file in os.listdir(src_path):\n",
        "            shutil.copy(os.path.join(src_path, file), os.path.join(dst_path, file))\n",
        "\n",
        "# Function to split into 80% train / 20% test\n",
        "def split_data(source_dir, train_dir, test_dir, ratio=0.9):\n",
        "    for class_name in os.listdir(source_dir):\n",
        "        class_path = os.path.join(source_dir, class_name)\n",
        "        files = os.listdir(class_path)\n",
        "        random.shuffle(files)\n",
        "        split_idx = int(len(files) * ratio)\n",
        "\n",
        "        train_files = files[:split_idx]\n",
        "        test_files = files[split_idx:]\n",
        "\n",
        "        for out_dir, file_list in [(train_dir, train_files), (test_dir, test_files)]:\n",
        "            class_out = os.path.join(out_dir, class_name)\n",
        "            os.makedirs(class_out, exist_ok=True)\n",
        "            for f in file_list:\n",
        "                shutil.copy(os.path.join(class_path, f), os.path.join(class_out, f))\n",
        "\n",
        "# Apply the split\n",
        "split_data(combined_dir, new_train_dir, new_test_dir)\n",
        "\n",
        "# Copy val data unchanged\n",
        "shutil.copytree(val_dir, new_val_dir, dirs_exist_ok=True)\n",
        "\n",
        "print(\"✅ Split complete!\")\n",
        "print(\"Train path:\", new_train_dir)\n",
        "print(\"Test path:\", new_test_dir)\n",
        "print(\"Validation path:\", new_val_dir)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f607279-d544-4a11-fbe4-9cfb3da1f0a4",
        "id": "Uxs7eWbS5j4d"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Split complete!\n",
            "Train path: /content/colon_data_fixed/train\n",
            "Test path: /content/colon_data_fixed/test\n",
            "Validation path: /content/colon_data_fixed/val\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Original train folder\n",
        "original_train_dir = '/content/colon_dataset/train'\n",
        "train_split_dir = '/content/colon_dataset/train_split'\n",
        "test_split_dir = '/content/colon_dataset/test_split'\n",
        "\n",
        "# Make new directories\n",
        "os.makedirs(train_split_dir, exist_ok=True)\n",
        "os.makedirs(test_split_dir, exist_ok=True)\n",
        "\n",
        "for class_name in os.listdir(original_train_dir):\n",
        "    class_dir = os.path.join(original_train_dir, class_name)\n",
        "    if os.path.isdir(class_dir):\n",
        "        images = os.listdir(class_dir)\n",
        "        train_imgs, test_imgs = train_test_split(images, test_size=0.1, random_state=42)\n",
        "\n",
        "        os.makedirs(os.path.join(train_split_dir, class_name), exist_ok=True)\n",
        "        os.makedirs(os.path.join(test_split_dir, class_name), exist_ok=True)\n",
        "\n",
        "        # Move images\n",
        "        for img in train_imgs:\n",
        "            shutil.copy2(os.path.join(class_dir, img), os.path.join(train_split_dir, class_name, img))\n",
        "        for img in test_imgs:\n",
        "            shutil.copy2(os.path.join(class_dir, img), os.path.join(test_split_dir, class_name, img))\n",
        "\n",
        "print(\"✅ Train/Test split (90/10) completed.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d6de2a5-3ba3-465e-8d8e-7d823a86e8a5",
        "id": "5y1KEoKd5j4d"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Train/Test split (90/10) completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = '/content/colon_dataset/train_split'\n",
        "test_dir = '/content/colon_dataset/test_split'\n",
        "val_dir = '/content/colon_dataset/val'\n",
        "\n",
        "# [Keep the rest of the code unchanged]\n"
      ],
      "metadata": {
        "id": "3pLDtJU25j4d"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "\n",
        "img_size = (224, 224)\n",
        "batch_size = 32\n",
        "\n",
        "train_dir = '/content/colon_dataset/train_split'\n",
        "test_dir = '/content/colon_dataset/test_split'\n",
        "val_dir = '/content/colon_dataset/val'\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6af56679-2637-4a62-8457-03ffdb9248d6",
        "id": "FLv3F25M5j4e"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2880 images belonging to 4 classes.\n",
            "Found 2000 images belonging to 4 classes.\n",
            "Found 640 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "img_size = (224, 224)\n",
        "batch_size = 32\n",
        "\n",
        "# Training and augmentation\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    '/content/colon_dataset/train_split',\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    '/content/colon_dataset/test_split',\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    '/content/colon_dataset/val',\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b8cd38a-f8a7-4350-df86-72aed13812dc",
        "id": "VO_5HLI05j4e"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2880 images belonging to 4 classes.\n",
            "Found 640 images belonging to 4 classes.\n",
            "Found 2000 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import DenseNet121\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dropout(0.5)(x)\n",
        "predictions = Dense(4, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Freeze base model\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "RAgSX8dN5j4e"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=10,\n",
        "    validation_data=val_generator\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a7c7dc3-3524-460b-b2ed-2384bd2b68df",
        "id": "bF7-TQW45j4e"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 767ms/step - accuracy: 0.2815 - loss: 2.0738 - val_accuracy: 0.5090 - val_loss: 1.1497\n",
            "Epoch 2/10\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 528ms/step - accuracy: 0.4336 - loss: 1.4888 - val_accuracy: 0.5865 - val_loss: 0.9875\n",
            "Epoch 3/10\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 883ms/step - accuracy: 0.5009 - loss: 1.2275 - val_accuracy: 0.6560 - val_loss: 0.8430\n",
            "Epoch 4/10\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 416ms/step - accuracy: 0.5664 - loss: 1.0658 - val_accuracy: 0.6975 - val_loss: 0.7540\n",
            "Epoch 5/10\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 419ms/step - accuracy: 0.6401 - loss: 0.8733 - val_accuracy: 0.7310 - val_loss: 0.6830\n",
            "Epoch 6/10\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 416ms/step - accuracy: 0.6809 - loss: 0.8066 - val_accuracy: 0.7565 - val_loss: 0.6400\n",
            "Epoch 7/10\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 417ms/step - accuracy: 0.7035 - loss: 0.7300 - val_accuracy: 0.7935 - val_loss: 0.5785\n",
            "Epoch 8/10\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 412ms/step - accuracy: 0.7388 - loss: 0.6606 - val_accuracy: 0.8015 - val_loss: 0.5480\n",
            "Epoch 9/10\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 410ms/step - accuracy: 0.7437 - loss: 0.6089 - val_accuracy: 0.8115 - val_loss: 0.5213\n",
            "Epoch 10/10\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 417ms/step - accuracy: 0.8132 - loss: 0.5140 - val_accuracy: 0.8215 - val_loss: 0.4948\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, average_precision_score, f1_score, precision_score, recall_score\n",
        "import numpy as np\n",
        "\n",
        "# Predict on test set\n",
        "y_true = test_generator.classes\n",
        "y_pred_probs = model.predict(test_generator)\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "# Basic metrics\n",
        "accuracy = np.mean(y_true == y_pred)\n",
        "f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "precision = precision_score(y_true, y_pred, average='weighted')\n",
        "recall = recall_score(y_true, y_pred, average='weighted')\n",
        "roc_auc = roc_auc_score(y_true, y_pred_probs, multi_class='ovr')\n",
        "aupr = average_precision_score(y_true, y_pred_probs, average='weighted')\n",
        "conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "report = classification_report(y_true, y_pred)\n",
        "\n",
        "# Print results\n",
        "print(f\"✅ Accuracy: {accuracy:.4f}\")\n",
        "print(f\"✅ ROC AUC Score: {roc_auc:.4f}\")\n",
        "print(f\"✅ AUPR Score: {aupr:.4f}\")\n",
        "print(f\"✅ Precision: {precision:.4f}\")\n",
        "print(f\"✅ Recall: {recall:.4f}\")\n",
        "print(f\"✅ F1 Score: {f1:.4f}\")\n",
        "print(f\"\\n✅ Confusion Matrix:\\n{conf_matrix}\")\n",
        "print(f\"\\n✅ Classification Report:\\n{report}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21d66548-0a6c-492f-8f03-0a41d3e8b6ca",
        "id": "Wbt1282J5j4e"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 217ms/step\n",
            "✅ Accuracy: 0.9437\n",
            "✅ ROC AUC Score: 0.9921\n",
            "✅ AUPR Score: 0.9777\n",
            "✅ Precision: 0.9434\n",
            "✅ Recall: 0.9437\n",
            "✅ F1 Score: 0.9434\n",
            "\n",
            "✅ Confusion Matrix:\n",
            "[[159   0   1   0]\n",
            " [  3 145  10   2]\n",
            " [  3  13 143   1]\n",
            " [  2   0   1 157]]\n",
            "\n",
            "✅ Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.99      0.97       160\n",
            "           1       0.92      0.91      0.91       160\n",
            "           2       0.92      0.89      0.91       160\n",
            "           3       0.98      0.98      0.98       160\n",
            "\n",
            "    accuracy                           0.94       640\n",
            "   macro avg       0.94      0.94      0.94       640\n",
            "weighted avg       0.94      0.94      0.94       640\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler, label_binarize\n",
        "from sklearn.metrics import (accuracy_score, roc_auc_score, average_precision_score,\n",
        "                             precision_score, recall_score, f1_score, confusion_matrix,\n",
        "                             classification_report)\n",
        "from tensorflow.keras.applications import DenseNet121\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import GaussianNoise, Dropout\n",
        "from tensorflow.keras.applications.densenet import preprocess_input\n",
        "from tqdm import tqdm\n",
        "\n",
        "# -----------------------------------\n",
        "# 1. Load DenseNet121 with Regularization\n",
        "# -----------------------------------\n",
        "base_model = DenseNet121(weights='imagenet', include_top=False, pooling='avg', input_shape=(224, 224, 3))\n",
        "\n",
        "# Add Gaussian Noise and Dropout for regularization\n",
        "x = GaussianNoise(0.1)(base_model.output)\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "# Final feature extraction model\n",
        "feature_model = Model(inputs=base_model.input, outputs=x)\n",
        "\n",
        "# -----------------------------------\n",
        "# 2. Feature Extraction Function\n",
        "# -----------------------------------\n",
        "def extract_features(generator, model):\n",
        "    features, labels = [], []\n",
        "    for i in tqdm(range(len(generator))):\n",
        "        x_batch, y_batch = generator[i]\n",
        "        x_batch = preprocess_input(x_batch)\n",
        "        batch_features = model.predict(x_batch, verbose=0)\n",
        "        features.append(batch_features)\n",
        "        labels.append(y_batch)\n",
        "    return np.vstack(features), np.concatenate(labels)\n",
        "\n",
        "# -----------------------------------\n",
        "# 3. Extract Features from Train/Val/Test Sets\n",
        "# (Assumes `train_generator`, `val_generator`, and `test_generator` are already defined)\n",
        "# -----------------------------------\n",
        "train_features, train_labels = extract_features(train_generator, feature_model)\n",
        "val_features, val_labels = extract_features(val_generator, feature_model)\n",
        "test_features, test_labels = extract_features(test_generator, feature_model)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cb3b4ef-f779-470e-dd22-2b4945c2fee3",
        "id": "FCyp-lu05j4e"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 90/90 [00:47<00:00,  1.89it/s]\n",
            "100%|██████████| 63/63 [00:35<00:00,  1.75it/s]\n",
            "100%|██████████| 20/20 [00:09<00:00,  2.21it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components=0.95)  # Keep 95% variance\n",
        "train_features = pca.fit_transform(train_features)\n",
        "val_features = pca.transform(val_features)\n",
        "test_features = pca.transform(test_features)\n"
      ],
      "metadata": {
        "id": "EDQdHjE-5j4e"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, roc_auc_score, average_precision_score,\n",
        "    precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
        ")\n",
        "from sklearn.preprocessing import label_binarize\n",
        "import numpy as np\n",
        "\n",
        "# Fix the label shape\n",
        "train_labels = np.argmax(train_labels, axis=1)\n",
        "test_labels = np.argmax(test_labels, axis=1)\n",
        "\n",
        "# Train SVM\n",
        "svm_clf = make_pipeline(StandardScaler(), SVC(kernel='rbf', probability=True, C=10, gamma='scale', random_state=42))\n",
        "svm_clf.fit(train_features, train_labels)\n",
        "\n",
        "# Predict\n",
        "pred_probs = svm_clf.predict_proba(test_features)\n",
        "pred_labels = np.argmax(pred_probs, axis=1)\n",
        "\n",
        "# Binarize for multi-class metrics\n",
        "n_classes = len(np.unique(test_labels))\n",
        "true_binarized = label_binarize(test_labels, classes=list(range(n_classes)))\n",
        "pred_binarized = label_binarize(pred_labels, classes=list(range(n_classes)))\n",
        "\n",
        "# Metrics\n",
        "accuracy = accuracy_score(test_labels, pred_labels)\n",
        "roc_auc = roc_auc_score(true_binarized, pred_probs, average='macro', multi_class='ovr')\n",
        "aupr = average_precision_score(true_binarized, pred_probs, average='macro')\n",
        "precision = precision_score(test_labels, pred_labels, average='macro')\n",
        "recall = recall_score(test_labels, pred_labels, average='macro')\n",
        "f1 = f1_score(test_labels, pred_labels, average='macro')\n",
        "cm = confusion_matrix(test_labels, pred_labels)\n",
        "report = classification_report(test_labels, pred_labels, target_names=test_generator.class_indices.keys())\n",
        "\n",
        "# Output\n",
        "print(f\"✅ Accuracy: {accuracy:.4f}\")\n",
        "print(f\"✅ ROC AUC Score: {roc_auc:.4f}\")\n",
        "print(f\"✅ AUPR Score: {aupr:.4f}\")\n",
        "print(f\"✅ Precision: {precision:.4f}\")\n",
        "print(f\"✅ Recall: {recall:.4f}\")\n",
        "print(f\"✅ F1 Score: {f1:.4f}\")\n",
        "print(\"\\n✅ Confusion Matrix:\")\n",
        "print(cm)\n",
        "print(\"\\n✅ Classification Report:\")\n",
        "print(report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e293f1ca-71b7-4983-c435-5c4f2081402c",
        "id": "AdLF5nEL5j4f"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Accuracy: 0.9578\n",
            "✅ ROC AUC Score: 0.9962\n",
            "✅ AUPR Score: 0.9905\n",
            "✅ Precision: 0.9579\n",
            "✅ Recall: 0.9578\n",
            "✅ F1 Score: 0.9577\n",
            "\n",
            "✅ Confusion Matrix:\n",
            "[[159   1   0   0]\n",
            " [  0 144  13   3]\n",
            " [  0   8 152   0]\n",
            " [  0   2   0 158]]\n",
            "\n",
            "✅ Classification Report:\n",
            "                      precision    recall  f1-score   support\n",
            "\n",
            "            0_normal       1.00      0.99      1.00       160\n",
            "1_ulcerative_colitis       0.93      0.90      0.91       160\n",
            "            2_polyps       0.92      0.95      0.94       160\n",
            "       3_esophagitis       0.98      0.99      0.98       160\n",
            "\n",
            "            accuracy                           0.96       640\n",
            "           macro avg       0.96      0.96      0.96       640\n",
            "        weighted avg       0.96      0.96      0.96       640\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler, label_binarize\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, roc_auc_score, average_precision_score,\n",
        "    precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
        ")\n",
        "import numpy as np\n",
        "\n",
        "# Optional: scale features (important for some classifiers, less so for RF but keeps consistency)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(train_features)\n",
        "X_test_scaled = scaler.transform(test_features)\n",
        "\n",
        "# Train Random Forest\n",
        "rf_clf = RandomForestClassifier(n_estimators=200, max_depth=20, random_state=42, n_jobs=-1)\n",
        "rf_clf.fit(X_train_scaled, train_labels)\n",
        "\n",
        "# Predict\n",
        "pred_probs = rf_clf.predict_proba(X_test_scaled)\n",
        "pred_labels = np.argmax(pred_probs, axis=1)\n",
        "\n",
        "# Binarize for multi-class AUC and AUPR\n",
        "n_classes = len(np.unique(test_labels))\n",
        "true_binarized = label_binarize(test_labels, classes=list(range(n_classes)))\n",
        "pred_binarized = label_binarize(pred_labels, classes=list(range(n_classes)))\n",
        "\n",
        "# Evaluation\n",
        "accuracy = accuracy_score(test_labels, pred_labels)\n",
        "roc_auc = roc_auc_score(true_binarized, pred_probs, average='macro', multi_class='ovr')\n",
        "aupr = average_precision_score(true_binarized, pred_probs, average='macro')\n",
        "precision = precision_score(test_labels, pred_labels, average='macro')\n",
        "recall = recall_score(test_labels, pred_labels, average='macro')\n",
        "f1 = f1_score(test_labels, pred_labels, average='macro')\n",
        "cm = confusion_matrix(test_labels, pred_labels)\n",
        "report = classification_report(test_labels, pred_labels)\n",
        "\n",
        "# Output\n",
        "print(f\"✅ Accuracy: {accuracy:.4f}\")\n",
        "print(f\"✅ ROC AUC Score: {roc_auc:.4f}\")\n",
        "print(f\"✅ AUPR Score: {aupr:.4f}\")\n",
        "print(f\"✅ Precision: {precision:.4f}\")\n",
        "print(f\"✅ Recall: {recall:.4f}\")\n",
        "print(f\"✅ F1 Score: {f1:.4f}\")\n",
        "\n",
        "print(\"\\n✅ Confusion Matrix:\")\n",
        "print(cm)\n",
        "\n",
        "print(\"\\n✅ Classification Report:\")\n",
        "print(report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddd6886f-367a-45be-9581-0eda5cc5908a",
        "id": "CAhl2hsF5j4f"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Accuracy: 0.9563\n",
            "✅ ROC AUC Score: 0.9952\n",
            "✅ AUPR Score: 0.9878\n",
            "✅ Precision: 0.9571\n",
            "✅ Recall: 0.9562\n",
            "✅ F1 Score: 0.9564\n",
            "\n",
            "✅ Confusion Matrix:\n",
            "[[158   2   0   0]\n",
            " [  0 151   8   1]\n",
            " [  0  12 147   1]\n",
            " [  1   3   0 156]]\n",
            "\n",
            "✅ Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       160\n",
            "           1       0.90      0.94      0.92       160\n",
            "           2       0.95      0.92      0.93       160\n",
            "           3       0.99      0.97      0.98       160\n",
            "\n",
            "    accuracy                           0.96       640\n",
            "   macro avg       0.96      0.96      0.96       640\n",
            "weighted avg       0.96      0.96      0.96       640\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.preprocessing import StandardScaler, label_binarize\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, roc_auc_score, average_precision_score,\n",
        "    precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
        ")\n",
        "import numpy as np\n",
        "\n",
        "# Scale features (helps even with XGBoost sometimes)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(train_features)\n",
        "X_test_scaled = scaler.transform(test_features)\n",
        "\n",
        "# Initialize XGBoost classifier\n",
        "xgb_clf = XGBClassifier(\n",
        "    n_estimators=200,\n",
        "    max_depth=8,\n",
        "    learning_rate=0.05,\n",
        "    objective='multi:softprob',\n",
        "    num_class=4,\n",
        "    use_label_encoder=False,\n",
        "    eval_metric='mlogloss',\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Train\n",
        "xgb_clf.fit(X_train_scaled, train_labels)\n",
        "\n",
        "# Predict probabilities and labels\n",
        "pred_probs = xgb_clf.predict_proba(X_test_scaled)\n",
        "pred_labels = np.argmax(pred_probs, axis=1)\n",
        "\n",
        "# Binarize for multi-class AUC and AUPR\n",
        "n_classes = len(np.unique(test_labels))\n",
        "true_binarized = label_binarize(test_labels, classes=list(range(n_classes)))\n",
        "pred_binarized = label_binarize(pred_labels, classes=list(range(n_classes)))\n",
        "\n",
        "# Evaluation metrics\n",
        "accuracy = accuracy_score(test_labels, pred_labels)\n",
        "roc_auc = roc_auc_score(true_binarized, pred_probs, average='macro', multi_class='ovr')\n",
        "aupr = average_precision_score(true_binarized, pred_probs, average='macro')\n",
        "precision = precision_score(test_labels, pred_labels, average='macro')\n",
        "recall = recall_score(test_labels, pred_labels, average='macro')\n",
        "f1 = f1_score(test_labels, pred_labels, average='macro')\n",
        "cm = confusion_matrix(test_labels, pred_labels)\n",
        "report = classification_report(test_labels, pred_labels)\n",
        "\n",
        "# Results\n",
        "print(f\"✅ Accuracy: {accuracy:.4f}\")\n",
        "print(f\"✅ ROC AUC Score: {roc_auc:.4f}\")\n",
        "print(f\"✅ AUPR Score: {aupr:.4f}\")\n",
        "print(f\"✅ Precision: {precision:.4f}\")\n",
        "print(f\"✅ Recall: {recall:.4f}\")\n",
        "print(f\"✅ F1 Score: {f1:.4f}\")\n",
        "\n",
        "print(\"\\n✅ Confusion Matrix:\")\n",
        "print(cm)\n",
        "\n",
        "print(\"\\n✅ Classification Report:\")\n",
        "print(report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e47d9b0-871c-4bad-9085-b2299be4d5d8",
        "id": "y44aapEe5j4f"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [16:34:37] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Accuracy: 0.9484\n",
            "✅ ROC AUC Score: 0.9953\n",
            "✅ AUPR Score: 0.9880\n",
            "✅ Precision: 0.9483\n",
            "✅ Recall: 0.9484\n",
            "✅ F1 Score: 0.9484\n",
            "\n",
            "✅ Confusion Matrix:\n",
            "[[159   1   0   0]\n",
            " [  0 144  13   3]\n",
            " [  0  12 147   1]\n",
            " [  1   2   0 157]]\n",
            "\n",
            "✅ Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       160\n",
            "           1       0.91      0.90      0.90       160\n",
            "           2       0.92      0.92      0.92       160\n",
            "           3       0.98      0.98      0.98       160\n",
            "\n",
            "    accuracy                           0.95       640\n",
            "   macro avg       0.95      0.95      0.95       640\n",
            "weighted avg       0.95      0.95      0.95       640\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.preprocessing import StandardScaler, label_binarize\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, roc_auc_score, average_precision_score,\n",
        "    precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
        ")\n",
        "import numpy as np\n",
        "\n",
        "# Scale features (very important for SVM)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(train_features)\n",
        "X_test_scaled = scaler.transform(test_features)\n",
        "\n",
        "# Define base models\n",
        "svm_clf = SVC(kernel='rbf', probability=True, C=2, gamma='scale', random_state=42)\n",
        "rf_clf = RandomForestClassifier(n_estimators=150, max_depth=12, random_state=42, n_jobs=-1)\n",
        "xgb_clf = XGBClassifier(\n",
        "    n_estimators=200,\n",
        "    max_depth=8,\n",
        "    learning_rate=0.05,\n",
        "    objective='multi:softprob',\n",
        "    num_class=4,\n",
        "    use_label_encoder=False,\n",
        "    eval_metric='mlogloss',\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Voting Classifier (soft voting based on probabilities)\n",
        "voting_clf = VotingClassifier(\n",
        "    estimators=[('svm', svm_clf), ('rf', rf_clf), ('xgb', xgb_clf)],\n",
        "    voting='soft',  # soft = use predicted probabilities\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Train ensemble\n",
        "voting_clf.fit(X_train_scaled, train_labels)\n",
        "\n",
        "# Predict\n",
        "pred_probs = voting_clf.predict_proba(X_test_scaled)\n",
        "pred_labels = np.argmax(pred_probs, axis=1)\n",
        "\n",
        "# Binarize for AUC/AUPR\n",
        "n_classes = len(np.unique(test_labels))\n",
        "true_binarized = label_binarize(test_labels, classes=list(range(n_classes)))\n",
        "pred_binarized = label_binarize(pred_labels, classes=list(range(n_classes)))\n",
        "\n",
        "# Metrics\n",
        "accuracy = accuracy_score(test_labels, pred_labels)\n",
        "roc_auc = roc_auc_score(true_binarized, pred_probs, average='macro', multi_class='ovr')\n",
        "aupr = average_precision_score(true_binarized, pred_probs, average='macro')\n",
        "precision = precision_score(test_labels, pred_labels, average='macro')\n",
        "recall = recall_score(test_labels, pred_labels, average='macro')\n",
        "f1 = f1_score(test_labels, pred_labels, average='macro')\n",
        "cm = confusion_matrix(test_labels, pred_labels)\n",
        "report = classification_report(test_labels, pred_labels)\n",
        "\n",
        "# Print results\n",
        "print(f\"✅ Accuracy: {accuracy:.4f}\")\n",
        "print(f\"✅ ROC AUC Score: {roc_auc:.4f}\")\n",
        "print(f\"✅ AUPR Score: {aupr:.4f}\")\n",
        "print(f\"✅ Precision: {precision:.4f}\")\n",
        "print(f\"✅ Recall: {recall:.4f}\")\n",
        "print(f\"✅ F1 Score: {f1:.4f}\")\n",
        "\n",
        "print(\"\\n✅ Confusion Matrix:\")\n",
        "print(cm)\n",
        "\n",
        "print(\"\\n✅ Classification Report:\")\n",
        "print(report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bc229a3-27c3-477e-bca6-ea7f3faa022e",
        "id": "PDXHIH7y5j4f"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Accuracy: 0.9641\n",
            "✅ ROC AUC Score: 0.9969\n",
            "✅ AUPR Score: 0.9930\n",
            "✅ Precision: 0.9641\n",
            "✅ Recall: 0.9641\n",
            "✅ F1 Score: 0.9640\n",
            "\n",
            "✅ Confusion Matrix:\n",
            "[[159   1   0   0]\n",
            " [  0 148  10   2]\n",
            " [  0   8 152   0]\n",
            " [  1   1   0 158]]\n",
            "\n",
            "✅ Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       160\n",
            "           1       0.94      0.93      0.93       160\n",
            "           2       0.94      0.95      0.94       160\n",
            "           3       0.99      0.99      0.99       160\n",
            "\n",
            "    accuracy                           0.96       640\n",
            "   macro avg       0.96      0.96      0.96       640\n",
            "weighted avg       0.96      0.96      0.96       640\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler, label_binarize\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, roc_auc_score, average_precision_score,\n",
        "    precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
        ")\n",
        "import numpy as np\n",
        "\n",
        "# Feature scaling (essential for SVM)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(train_features)\n",
        "X_test_scaled = scaler.transform(test_features)\n",
        "\n",
        "\n",
        "# Meta learner\n",
        "meta_learner = LogisticRegression(max_iter=1000, multi_class='multinomial', solver='lbfgs')\n",
        "\n",
        "# Stacking classifier\n",
        "stacking_clf = StackingClassifier(\n",
        "    estimators=[\n",
        "        ('svm', svm_clf),\n",
        "        ('rf', rf_clf),\n",
        "        ('xgb', xgb_clf)\n",
        "    ],\n",
        "    final_estimator=meta_learner,\n",
        "    stack_method='predict_proba',  # Important for multiclass classification\n",
        "    cv=5,\n",
        "    n_jobs=-1,\n",
        "    passthrough=False\n",
        ")\n",
        "\n",
        "# Train ensemble\n",
        "stacking_clf.fit(X_train_scaled, train_labels)\n",
        "\n",
        "# Predict\n",
        "pred_probs = stacking_clf.predict_proba(X_test_scaled)\n",
        "pred_labels = np.argmax(pred_probs, axis=1)\n",
        "\n",
        "# Binarize for multiclass AUC/AUPR\n",
        "n_classes = len(np.unique(test_labels))\n",
        "true_binarized = label_binarize(test_labels, classes=list(range(n_classes)))\n",
        "pred_binarized = label_binarize(pred_labels, classes=list(range(n_classes)))\n",
        "\n",
        "# Evaluation\n",
        "accuracy = accuracy_score(test_labels, pred_labels)\n",
        "roc_auc = roc_auc_score(true_binarized, pred_probs, average='macro', multi_class='ovr')\n",
        "aupr = average_precision_score(true_binarized, pred_probs, average='macro')\n",
        "precision = precision_score(test_labels, pred_labels, average='macro')\n",
        "recall = recall_score(test_labels, pred_labels, average='macro')\n",
        "f1 = f1_score(test_labels, pred_labels, average='macro')\n",
        "cm = confusion_matrix(test_labels, pred_labels)\n",
        "report = classification_report(test_labels, pred_labels)\n",
        "\n",
        "# Print metrics\n",
        "print(f\"✅ Accuracy: {accuracy:.4f}\")\n",
        "print(f\"✅ ROC AUC Score: {roc_auc:.4f}\")\n",
        "print(f\"✅ AUPR Score: {aupr:.4f}\")\n",
        "print(f\"✅ Precision: {precision:.4f}\")\n",
        "print(f\"✅ Recall: {recall:.4f}\")\n",
        "print(f\"✅ F1 Score: {f1:.4f}\")\n",
        "print(\"\\n✅ Confusion Matrix:\")\n",
        "print(cm)\n",
        "print(\"\\n✅ Classification Report:\")\n",
        "print(report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab76d5c0-ed2b-453f-ff38-e82556c26a27",
        "id": "fuIkXiSL5j4f"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Accuracy: 0.9656\n",
            "✅ ROC AUC Score: 0.9975\n",
            "✅ AUPR Score: 0.9937\n",
            "✅ Precision: 0.9659\n",
            "✅ Recall: 0.9656\n",
            "✅ F1 Score: 0.9656\n",
            "\n",
            "✅ Confusion Matrix:\n",
            "[[159   0   1   0]\n",
            " [  0 147  11   2]\n",
            " [  0   6 154   0]\n",
            " [  0   2   0 158]]\n",
            "\n",
            "✅ Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      1.00       160\n",
            "           1       0.95      0.92      0.93       160\n",
            "           2       0.93      0.96      0.94       160\n",
            "           3       0.99      0.99      0.99       160\n",
            "\n",
            "    accuracy                           0.97       640\n",
            "   macro avg       0.97      0.97      0.97       640\n",
            "weighted avg       0.97      0.97      0.97       640\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rXoSP8rA5tSg"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZUtkqtof6vOW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "70 30"
      ],
      "metadata": {
        "id": "Bj6bq5ly69Fq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "\n",
        "# Base original data directory\n",
        "base_dir = \"/content/colon_dataset\"\n",
        "train_dir = os.path.join(base_dir, \"train\")\n",
        "val_dir = os.path.join(base_dir, \"val\")\n",
        "test_dir = os.path.join(base_dir, \"test\")\n",
        "\n",
        "# New root for fixed structure\n",
        "fixed_base_dir = \"/content/colon_data_fixed\"\n",
        "combined_dir = os.path.join(fixed_base_dir, \"all_data\")\n",
        "new_train_dir = os.path.join(fixed_base_dir, \"train\")\n",
        "new_test_dir = os.path.join(fixed_base_dir, \"test\")\n",
        "new_val_dir = os.path.join(fixed_base_dir, \"val\")\n",
        "\n",
        "# Create fixed base directory\n",
        "os.makedirs(combined_dir, exist_ok=True)\n",
        "\n",
        "# Combine train + test data into one \"all_data\" folder\n",
        "for source_folder in [train_dir, test_dir]:\n",
        "    for class_name in os.listdir(source_folder):\n",
        "        src_path = os.path.join(source_folder, class_name)\n",
        "        dst_path = os.path.join(combined_dir, class_name)\n",
        "        os.makedirs(dst_path, exist_ok=True)\n",
        "        for file in os.listdir(src_path):\n",
        "            shutil.copy(os.path.join(src_path, file), os.path.join(dst_path, file))\n",
        "\n",
        "# Function to split into 80% train / 20% test\n",
        "def split_data(source_dir, train_dir, test_dir, ratio=0.7):\n",
        "    for class_name in os.listdir(source_dir):\n",
        "        class_path = os.path.join(source_dir, class_name)\n",
        "        files = os.listdir(class_path)\n",
        "        random.shuffle(files)\n",
        "        split_idx = int(len(files) * ratio)\n",
        "\n",
        "        train_files = files[:split_idx]\n",
        "        test_files = files[split_idx:]\n",
        "\n",
        "        for out_dir, file_list in [(train_dir, train_files), (test_dir, test_files)]:\n",
        "            class_out = os.path.join(out_dir, class_name)\n",
        "            os.makedirs(class_out, exist_ok=True)\n",
        "            for f in file_list:\n",
        "                shutil.copy(os.path.join(class_path, f), os.path.join(class_out, f))\n",
        "\n",
        "# Apply the split\n",
        "split_data(combined_dir, new_train_dir, new_test_dir)\n",
        "\n",
        "# Copy val data unchanged\n",
        "shutil.copytree(val_dir, new_val_dir, dirs_exist_ok=True)\n",
        "\n",
        "print(\"✅ Split complete!\")\n",
        "print(\"Train path:\", new_train_dir)\n",
        "print(\"Test path:\", new_test_dir)\n",
        "print(\"Validation path:\", new_val_dir)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc39301a-8284-4056-e5da-1aaef3ced234",
        "id": "x3b_yCSJ6vf5"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Split complete!\n",
            "Train path: /content/colon_data_fixed/train\n",
            "Test path: /content/colon_data_fixed/test\n",
            "Validation path: /content/colon_data_fixed/val\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Original train folder\n",
        "original_train_dir = '/content/colon_dataset/train'\n",
        "train_split_dir = '/content/colon_dataset/train_split'\n",
        "test_split_dir = '/content/colon_dataset/test_split'\n",
        "\n",
        "# Make new directories\n",
        "os.makedirs(train_split_dir, exist_ok=True)\n",
        "os.makedirs(test_split_dir, exist_ok=True)\n",
        "\n",
        "for class_name in os.listdir(original_train_dir):\n",
        "    class_dir = os.path.join(original_train_dir, class_name)\n",
        "    if os.path.isdir(class_dir):\n",
        "        images = os.listdir(class_dir)\n",
        "        train_imgs, test_imgs = train_test_split(images, test_size=0.3, random_state=42)\n",
        "\n",
        "        os.makedirs(os.path.join(train_split_dir, class_name), exist_ok=True)\n",
        "        os.makedirs(os.path.join(test_split_dir, class_name), exist_ok=True)\n",
        "\n",
        "        # Move images\n",
        "        for img in train_imgs:\n",
        "            shutil.copy2(os.path.join(class_dir, img), os.path.join(train_split_dir, class_name, img))\n",
        "        for img in test_imgs:\n",
        "            shutil.copy2(os.path.join(class_dir, img), os.path.join(test_split_dir, class_name, img))\n",
        "\n",
        "print(\"✅ Train/Test split (70/30) completed.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f9abdff-1d54-496c-c32b-895285ed3aa9",
        "id": "itLXfu1m6vf6"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Train/Test split (70/30) completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = '/content/colon_dataset/train_split'\n",
        "test_dir = '/content/colon_dataset/test_split'\n",
        "val_dir = '/content/colon_dataset/val'\n",
        "\n",
        "# [Keep the rest of the code unchanged]\n"
      ],
      "metadata": {
        "id": "_r54b1wG6vf6"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "\n",
        "img_size = (224, 224)\n",
        "batch_size = 32\n",
        "\n",
        "train_dir = '/content/colon_dataset/train_split'\n",
        "test_dir = '/content/colon_dataset/test_split'\n",
        "val_dir = '/content/colon_dataset/val'\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad8b6eb1-9fae-47d6-d8db-5de1696cf250",
        "id": "e9tiXOHZ6vf6"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2880 images belonging to 4 classes.\n",
            "Found 2000 images belonging to 4 classes.\n",
            "Found 960 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "img_size = (224, 224)\n",
        "batch_size = 32\n",
        "\n",
        "# Training and augmentation\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    '/content/colon_dataset/train_split',\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    '/content/colon_dataset/test_split',\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    '/content/colon_dataset/val',\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd30fc37-c072-4a43-f272-30a5a7401c32",
        "id": "TsG6rVYV6vf7"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2880 images belonging to 4 classes.\n",
            "Found 960 images belonging to 4 classes.\n",
            "Found 2000 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import DenseNet121\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dropout(0.5)(x)\n",
        "predictions = Dense(4, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Freeze base model\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "e6g-SICT6vf7"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=10,\n",
        "    validation_data=val_generator\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ec6f766-ecb9-4260-8b01-0596034dfd3a",
        "id": "RBm8Y2XK6vf7"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 619ms/step - accuracy: 0.2732 - loss: 2.1259 - val_accuracy: 0.3430 - val_loss: 1.3599\n",
            "Epoch 2/10\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 427ms/step - accuracy: 0.3644 - loss: 1.5905 - val_accuracy: 0.4600 - val_loss: 1.1475\n",
            "Epoch 3/10\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 416ms/step - accuracy: 0.4767 - loss: 1.3316 - val_accuracy: 0.5900 - val_loss: 0.9759\n",
            "Epoch 4/10\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 424ms/step - accuracy: 0.5386 - loss: 1.0752 - val_accuracy: 0.5950 - val_loss: 0.9229\n",
            "Epoch 5/10\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 425ms/step - accuracy: 0.6043 - loss: 0.9662 - val_accuracy: 0.6495 - val_loss: 0.8279\n",
            "Epoch 6/10\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 421ms/step - accuracy: 0.6847 - loss: 0.8023 - val_accuracy: 0.6965 - val_loss: 0.7470\n",
            "Epoch 7/10\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 417ms/step - accuracy: 0.6961 - loss: 0.7476 - val_accuracy: 0.7030 - val_loss: 0.7103\n",
            "Epoch 8/10\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 414ms/step - accuracy: 0.7308 - loss: 0.6546 - val_accuracy: 0.7200 - val_loss: 0.6723\n",
            "Epoch 9/10\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 427ms/step - accuracy: 0.7449 - loss: 0.6236 - val_accuracy: 0.7615 - val_loss: 0.6087\n",
            "Epoch 10/10\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 416ms/step - accuracy: 0.7910 - loss: 0.5585 - val_accuracy: 0.7680 - val_loss: 0.5854\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, average_precision_score, f1_score, precision_score, recall_score\n",
        "import numpy as np\n",
        "\n",
        "# Predict on test set\n",
        "y_true = test_generator.classes\n",
        "y_pred_probs = model.predict(test_generator)\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "# Basic metrics\n",
        "accuracy = np.mean(y_true == y_pred)\n",
        "f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "precision = precision_score(y_true, y_pred, average='weighted')\n",
        "recall = recall_score(y_true, y_pred, average='weighted')\n",
        "roc_auc = roc_auc_score(y_true, y_pred_probs, multi_class='ovr')\n",
        "aupr = average_precision_score(y_true, y_pred_probs, average='weighted')\n",
        "conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "report = classification_report(y_true, y_pred)\n",
        "\n",
        "# Print results\n",
        "print(f\"✅ Accuracy: {accuracy:.4f}\")\n",
        "print(f\"✅ ROC AUC Score: {roc_auc:.4f}\")\n",
        "print(f\"✅ AUPR Score: {aupr:.4f}\")\n",
        "print(f\"✅ Precision: {precision:.4f}\")\n",
        "print(f\"✅ Recall: {recall:.4f}\")\n",
        "print(f\"✅ F1 Score: {f1:.4f}\")\n",
        "print(f\"\\n✅ Confusion Matrix:\\n{conf_matrix}\")\n",
        "print(f\"\\n✅ Classification Report:\\n{report}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2b88d98-2003-4506-94de-f4afde401ba1",
        "id": "UfIvO16p6vf7"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 251ms/step\n",
            "✅ Accuracy: 0.9396\n",
            "✅ ROC AUC Score: 0.9924\n",
            "✅ AUPR Score: 0.9806\n",
            "✅ Precision: 0.9391\n",
            "✅ Recall: 0.9396\n",
            "✅ F1 Score: 0.9392\n",
            "\n",
            "✅ Confusion Matrix:\n",
            "[[238   0   2   0]\n",
            " [  6 215  16   3]\n",
            " [  4  19 214   3]\n",
            " [  2   1   2 235]]\n",
            "\n",
            "✅ Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.99      0.97       240\n",
            "           1       0.91      0.90      0.91       240\n",
            "           2       0.91      0.89      0.90       240\n",
            "           3       0.98      0.98      0.98       240\n",
            "\n",
            "    accuracy                           0.94       960\n",
            "   macro avg       0.94      0.94      0.94       960\n",
            "weighted avg       0.94      0.94      0.94       960\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler, label_binarize\n",
        "from sklearn.metrics import (accuracy_score, roc_auc_score, average_precision_score,\n",
        "                             precision_score, recall_score, f1_score, confusion_matrix,\n",
        "                             classification_report)\n",
        "from tensorflow.keras.applications import DenseNet121\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import GaussianNoise, Dropout\n",
        "from tensorflow.keras.applications.densenet import preprocess_input\n",
        "from tqdm import tqdm\n",
        "\n",
        "# -----------------------------------\n",
        "# 1. Load DenseNet121 with Regularization\n",
        "# -----------------------------------\n",
        "base_model = DenseNet121(weights='imagenet', include_top=False, pooling='avg', input_shape=(224, 224, 3))\n",
        "\n",
        "# Add Gaussian Noise and Dropout for regularization\n",
        "x = GaussianNoise(0.1)(base_model.output)\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "# Final feature extraction model\n",
        "feature_model = Model(inputs=base_model.input, outputs=x)\n",
        "\n",
        "# -----------------------------------\n",
        "# 2. Feature Extraction Function\n",
        "# -----------------------------------\n",
        "def extract_features(generator, model):\n",
        "    features, labels = [], []\n",
        "    for i in tqdm(range(len(generator))):\n",
        "        x_batch, y_batch = generator[i]\n",
        "        x_batch = preprocess_input(x_batch)\n",
        "        batch_features = model.predict(x_batch, verbose=0)\n",
        "        features.append(batch_features)\n",
        "        labels.append(y_batch)\n",
        "    return np.vstack(features), np.concatenate(labels)\n",
        "\n",
        "# -----------------------------------\n",
        "# 3. Extract Features from Train/Val/Test Sets\n",
        "# (Assumes `train_generator`, `val_generator`, and `test_generator` are already defined)\n",
        "# -----------------------------------\n",
        "train_features, train_labels = extract_features(train_generator, feature_model)\n",
        "val_features, val_labels = extract_features(val_generator, feature_model)\n",
        "test_features, test_labels = extract_features(test_generator, feature_model)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6d3a3e1-dc8a-4d34-d6c6-e5b655b1f2d0",
        "id": "m6rt-50k6vf7"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 90/90 [00:45<00:00,  1.96it/s]\n",
            "100%|██████████| 63/63 [00:36<00:00,  1.75it/s]\n",
            "100%|██████████| 30/30 [00:12<00:00,  2.44it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components=0.95)  # Keep 95% variance\n",
        "train_features = pca.fit_transform(train_features)\n",
        "val_features = pca.transform(val_features)\n",
        "test_features = pca.transform(test_features)\n"
      ],
      "metadata": {
        "id": "nbpvcxad6vf8"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, roc_auc_score, average_precision_score,\n",
        "    precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
        ")\n",
        "from sklearn.preprocessing import label_binarize\n",
        "import numpy as np\n",
        "\n",
        "# Fix the label shape\n",
        "train_labels = np.argmax(train_labels, axis=1)\n",
        "test_labels = np.argmax(test_labels, axis=1)\n",
        "\n",
        "# Train SVM\n",
        "svm_clf = make_pipeline(StandardScaler(), SVC(kernel='rbf', probability=True, C=10, gamma='scale', random_state=42))\n",
        "svm_clf.fit(train_features, train_labels)\n",
        "\n",
        "# Predict\n",
        "pred_probs = svm_clf.predict_proba(test_features)\n",
        "pred_labels = np.argmax(pred_probs, axis=1)\n",
        "\n",
        "# Binarize for multi-class metrics\n",
        "n_classes = len(np.unique(test_labels))\n",
        "true_binarized = label_binarize(test_labels, classes=list(range(n_classes)))\n",
        "pred_binarized = label_binarize(pred_labels, classes=list(range(n_classes)))\n",
        "\n",
        "# Metrics\n",
        "accuracy = accuracy_score(test_labels, pred_labels)\n",
        "roc_auc = roc_auc_score(true_binarized, pred_probs, average='macro', multi_class='ovr')\n",
        "aupr = average_precision_score(true_binarized, pred_probs, average='macro')\n",
        "precision = precision_score(test_labels, pred_labels, average='macro')\n",
        "recall = recall_score(test_labels, pred_labels, average='macro')\n",
        "f1 = f1_score(test_labels, pred_labels, average='macro')\n",
        "cm = confusion_matrix(test_labels, pred_labels)\n",
        "report = classification_report(test_labels, pred_labels, target_names=test_generator.class_indices.keys())\n",
        "\n",
        "# Output\n",
        "print(f\"✅ Accuracy: {accuracy:.4f}\")\n",
        "print(f\"✅ ROC AUC Score: {roc_auc:.4f}\")\n",
        "print(f\"✅ AUPR Score: {aupr:.4f}\")\n",
        "print(f\"✅ Precision: {precision:.4f}\")\n",
        "print(f\"✅ Recall: {recall:.4f}\")\n",
        "print(f\"✅ F1 Score: {f1:.4f}\")\n",
        "print(\"\\n✅ Confusion Matrix:\")\n",
        "print(cm)\n",
        "print(\"\\n✅ Classification Report:\")\n",
        "print(report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d21072ba-9f6d-49e3-872c-55df9acad1a9",
        "id": "HcFRvEVw6vf8"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Accuracy: 0.9719\n",
            "✅ ROC AUC Score: 0.9979\n",
            "✅ AUPR Score: 0.9950\n",
            "✅ Precision: 0.9719\n",
            "✅ Recall: 0.9719\n",
            "✅ F1 Score: 0.9718\n",
            "\n",
            "✅ Confusion Matrix:\n",
            "[[239   1   0   0]\n",
            " [  0 224  13   3]\n",
            " [  0   8 232   0]\n",
            " [  0   2   0 238]]\n",
            "\n",
            "✅ Classification Report:\n",
            "                      precision    recall  f1-score   support\n",
            "\n",
            "            0_normal       1.00      1.00      1.00       240\n",
            "1_ulcerative_colitis       0.95      0.93      0.94       240\n",
            "            2_polyps       0.95      0.97      0.96       240\n",
            "       3_esophagitis       0.99      0.99      0.99       240\n",
            "\n",
            "            accuracy                           0.97       960\n",
            "           macro avg       0.97      0.97      0.97       960\n",
            "        weighted avg       0.97      0.97      0.97       960\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler, label_binarize\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, roc_auc_score, average_precision_score,\n",
        "    precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
        ")\n",
        "import numpy as np\n",
        "\n",
        "# Optional: scale features (important for some classifiers, less so for RF but keeps consistency)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(train_features)\n",
        "X_test_scaled = scaler.transform(test_features)\n",
        "\n",
        "# Train Random Forest\n",
        "rf_clf = RandomForestClassifier(n_estimators=200, max_depth=20, random_state=42, n_jobs=-1)\n",
        "rf_clf.fit(X_train_scaled, train_labels)\n",
        "\n",
        "# Predict\n",
        "pred_probs = rf_clf.predict_proba(X_test_scaled)\n",
        "pred_labels = np.argmax(pred_probs, axis=1)\n",
        "\n",
        "# Binarize for multi-class AUC and AUPR\n",
        "n_classes = len(np.unique(test_labels))\n",
        "true_binarized = label_binarize(test_labels, classes=list(range(n_classes)))\n",
        "pred_binarized = label_binarize(pred_labels, classes=list(range(n_classes)))\n",
        "\n",
        "# Evaluation\n",
        "accuracy = accuracy_score(test_labels, pred_labels)\n",
        "roc_auc = roc_auc_score(true_binarized, pred_probs, average='macro', multi_class='ovr')\n",
        "aupr = average_precision_score(true_binarized, pred_probs, average='macro')\n",
        "precision = precision_score(test_labels, pred_labels, average='macro')\n",
        "recall = recall_score(test_labels, pred_labels, average='macro')\n",
        "f1 = f1_score(test_labels, pred_labels, average='macro')\n",
        "cm = confusion_matrix(test_labels, pred_labels)\n",
        "report = classification_report(test_labels, pred_labels)\n",
        "\n",
        "# Output\n",
        "print(f\"✅ Accuracy: {accuracy:.4f}\")\n",
        "print(f\"✅ ROC AUC Score: {roc_auc:.4f}\")\n",
        "print(f\"✅ AUPR Score: {aupr:.4f}\")\n",
        "print(f\"✅ Precision: {precision:.4f}\")\n",
        "print(f\"✅ Recall: {recall:.4f}\")\n",
        "print(f\"✅ F1 Score: {f1:.4f}\")\n",
        "\n",
        "print(\"\\n✅ Confusion Matrix:\")\n",
        "print(cm)\n",
        "\n",
        "print(\"\\n✅ Classification Report:\")\n",
        "print(report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "644768f6-6eea-49ee-aae1-d8fd30bf41c5",
        "id": "mmjTHVwl6vf8"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Accuracy: 0.9698\n",
            "✅ ROC AUC Score: 0.9979\n",
            "✅ AUPR Score: 0.9945\n",
            "✅ Precision: 0.9700\n",
            "✅ Recall: 0.9698\n",
            "✅ F1 Score: 0.9699\n",
            "\n",
            "✅ Confusion Matrix:\n",
            "[[238   2   0   0]\n",
            " [  0 229  10   1]\n",
            " [  0  11 228   1]\n",
            " [  1   3   0 236]]\n",
            "\n",
            "✅ Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      0.99       240\n",
            "           1       0.93      0.95      0.94       240\n",
            "           2       0.96      0.95      0.95       240\n",
            "           3       0.99      0.98      0.99       240\n",
            "\n",
            "    accuracy                           0.97       960\n",
            "   macro avg       0.97      0.97      0.97       960\n",
            "weighted avg       0.97      0.97      0.97       960\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.preprocessing import StandardScaler, label_binarize\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, roc_auc_score, average_precision_score,\n",
        "    precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
        ")\n",
        "import numpy as np\n",
        "\n",
        "# Scale features (helps even with XGBoost sometimes)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(train_features)\n",
        "X_test_scaled = scaler.transform(test_features)\n",
        "\n",
        "# Initialize XGBoost classifier\n",
        "xgb_clf = XGBClassifier(\n",
        "    n_estimators=200,\n",
        "    max_depth=8,\n",
        "    learning_rate=0.05,\n",
        "    objective='multi:softprob',\n",
        "    num_class=4,\n",
        "    use_label_encoder=False,\n",
        "    eval_metric='mlogloss',\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Train\n",
        "xgb_clf.fit(X_train_scaled, train_labels)\n",
        "\n",
        "# Predict probabilities and labels\n",
        "pred_probs = xgb_clf.predict_proba(X_test_scaled)\n",
        "pred_labels = np.argmax(pred_probs, axis=1)\n",
        "\n",
        "# Binarize for multi-class AUC and AUPR\n",
        "n_classes = len(np.unique(test_labels))\n",
        "true_binarized = label_binarize(test_labels, classes=list(range(n_classes)))\n",
        "pred_binarized = label_binarize(pred_labels, classes=list(range(n_classes)))\n",
        "\n",
        "# Evaluation metrics\n",
        "accuracy = accuracy_score(test_labels, pred_labels)\n",
        "roc_auc = roc_auc_score(true_binarized, pred_probs, average='macro', multi_class='ovr')\n",
        "aupr = average_precision_score(true_binarized, pred_probs, average='macro')\n",
        "precision = precision_score(test_labels, pred_labels, average='macro')\n",
        "recall = recall_score(test_labels, pred_labels, average='macro')\n",
        "f1 = f1_score(test_labels, pred_labels, average='macro')\n",
        "cm = confusion_matrix(test_labels, pred_labels)\n",
        "report = classification_report(test_labels, pred_labels)\n",
        "\n",
        "# Results\n",
        "print(f\"✅ Accuracy: {accuracy:.4f}\")\n",
        "print(f\"✅ ROC AUC Score: {roc_auc:.4f}\")\n",
        "print(f\"✅ AUPR Score: {aupr:.4f}\")\n",
        "print(f\"✅ Precision: {precision:.4f}\")\n",
        "print(f\"✅ Recall: {recall:.4f}\")\n",
        "print(f\"✅ F1 Score: {f1:.4f}\")\n",
        "\n",
        "print(\"\\n✅ Confusion Matrix:\")\n",
        "print(cm)\n",
        "\n",
        "print(\"\\n✅ Classification Report:\")\n",
        "print(report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84e9d3b1-c2a9-4abb-b975-f887aab568ab",
        "id": "3kDqcCMg6vf8"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [16:45:03] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Accuracy: 0.9656\n",
            "✅ ROC AUC Score: 0.9976\n",
            "✅ AUPR Score: 0.9940\n",
            "✅ Precision: 0.9657\n",
            "✅ Recall: 0.9656\n",
            "✅ F1 Score: 0.9657\n",
            "\n",
            "✅ Confusion Matrix:\n",
            "[[238   1   1   0]\n",
            " [  0 225  13   2]\n",
            " [  0  12 227   1]\n",
            " [  1   2   0 237]]\n",
            "\n",
            "✅ Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      0.99       240\n",
            "           1       0.94      0.94      0.94       240\n",
            "           2       0.94      0.95      0.94       240\n",
            "           3       0.99      0.99      0.99       240\n",
            "\n",
            "    accuracy                           0.97       960\n",
            "   macro avg       0.97      0.97      0.97       960\n",
            "weighted avg       0.97      0.97      0.97       960\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.preprocessing import StandardScaler, label_binarize\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, roc_auc_score, average_precision_score,\n",
        "    precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
        ")\n",
        "import numpy as np\n",
        "\n",
        "# Scale features (very important for SVM)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(train_features)\n",
        "X_test_scaled = scaler.transform(test_features)\n",
        "\n",
        "# Define base models\n",
        "svm_clf = SVC(kernel='rbf', probability=True, C=2, gamma='scale', random_state=42)\n",
        "rf_clf = RandomForestClassifier(n_estimators=150, max_depth=12, random_state=42, n_jobs=-1)\n",
        "xgb_clf = XGBClassifier(\n",
        "    n_estimators=200,\n",
        "    max_depth=8,\n",
        "    learning_rate=0.05,\n",
        "    objective='multi:softprob',\n",
        "    num_class=4,\n",
        "    use_label_encoder=False,\n",
        "    eval_metric='mlogloss',\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Voting Classifier (soft voting based on probabilities)\n",
        "voting_clf = VotingClassifier(\n",
        "    estimators=[('svm', svm_clf), ('rf', rf_clf), ('xgb', xgb_clf)],\n",
        "    voting='soft',  # soft = use predicted probabilities\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Train ensemble\n",
        "voting_clf.fit(X_train_scaled, train_labels)\n",
        "\n",
        "# Predict\n",
        "pred_probs = voting_clf.predict_proba(X_test_scaled)\n",
        "pred_labels = np.argmax(pred_probs, axis=1)\n",
        "\n",
        "# Binarize for AUC/AUPR\n",
        "n_classes = len(np.unique(test_labels))\n",
        "true_binarized = label_binarize(test_labels, classes=list(range(n_classes)))\n",
        "pred_binarized = label_binarize(pred_labels, classes=list(range(n_classes)))\n",
        "\n",
        "# Metrics\n",
        "accuracy = accuracy_score(test_labels, pred_labels)\n",
        "roc_auc = roc_auc_score(true_binarized, pred_probs, average='macro', multi_class='ovr')\n",
        "aupr = average_precision_score(true_binarized, pred_probs, average='macro')\n",
        "precision = precision_score(test_labels, pred_labels, average='macro')\n",
        "recall = recall_score(test_labels, pred_labels, average='macro')\n",
        "f1 = f1_score(test_labels, pred_labels, average='macro')\n",
        "cm = confusion_matrix(test_labels, pred_labels)\n",
        "report = classification_report(test_labels, pred_labels)\n",
        "\n",
        "# Print results\n",
        "print(f\"✅ Accuracy: {accuracy:.4f}\")\n",
        "print(f\"✅ ROC AUC Score: {roc_auc:.4f}\")\n",
        "print(f\"✅ AUPR Score: {aupr:.4f}\")\n",
        "print(f\"✅ Precision: {precision:.4f}\")\n",
        "print(f\"✅ Recall: {recall:.4f}\")\n",
        "print(f\"✅ F1 Score: {f1:.4f}\")\n",
        "\n",
        "print(\"\\n✅ Confusion Matrix:\")\n",
        "print(cm)\n",
        "\n",
        "print(\"\\n✅ Classification Report:\")\n",
        "print(report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a42af5e-be8a-451f-e035-c198ee4dfa58",
        "id": "mVS2FL3M6vf8"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Accuracy: 0.9760\n",
            "✅ ROC AUC Score: 0.9985\n",
            "✅ AUPR Score: 0.9965\n",
            "✅ Precision: 0.9761\n",
            "✅ Recall: 0.9760\n",
            "✅ F1 Score: 0.9761\n",
            "\n",
            "✅ Confusion Matrix:\n",
            "[[239   1   0   0]\n",
            " [  0 228  11   1]\n",
            " [  0   8 232   0]\n",
            " [  1   1   0 238]]\n",
            "\n",
            "✅ Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       240\n",
            "           1       0.96      0.95      0.95       240\n",
            "           2       0.95      0.97      0.96       240\n",
            "           3       1.00      0.99      0.99       240\n",
            "\n",
            "    accuracy                           0.98       960\n",
            "   macro avg       0.98      0.98      0.98       960\n",
            "weighted avg       0.98      0.98      0.98       960\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler, label_binarize\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, roc_auc_score, average_precision_score,\n",
        "    precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
        ")\n",
        "import numpy as np\n",
        "\n",
        "# Feature scaling (essential for SVM)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(train_features)\n",
        "X_test_scaled = scaler.transform(test_features)\n",
        "\n",
        "\n",
        "# Meta learner\n",
        "meta_learner = LogisticRegression(max_iter=1000, multi_class='multinomial', solver='lbfgs')\n",
        "\n",
        "# Stacking classifier\n",
        "stacking_clf = StackingClassifier(\n",
        "    estimators=[\n",
        "        ('svm', svm_clf),\n",
        "        ('rf', rf_clf),\n",
        "        ('xgb', xgb_clf)\n",
        "    ],\n",
        "    final_estimator=meta_learner,\n",
        "    stack_method='predict_proba',  # Important for multiclass classification\n",
        "    cv=5,\n",
        "    n_jobs=-1,\n",
        "    passthrough=False\n",
        ")\n",
        "\n",
        "# Train ensemble\n",
        "stacking_clf.fit(X_train_scaled, train_labels)\n",
        "\n",
        "# Predict\n",
        "pred_probs = stacking_clf.predict_proba(X_test_scaled)\n",
        "pred_labels = np.argmax(pred_probs, axis=1)\n",
        "\n",
        "# Binarize for multiclass AUC/AUPR\n",
        "n_classes = len(np.unique(test_labels))\n",
        "true_binarized = label_binarize(test_labels, classes=list(range(n_classes)))\n",
        "pred_binarized = label_binarize(pred_labels, classes=list(range(n_classes)))\n",
        "\n",
        "# Evaluation\n",
        "accuracy = accuracy_score(test_labels, pred_labels)\n",
        "roc_auc = roc_auc_score(true_binarized, pred_probs, average='macro', multi_class='ovr')\n",
        "aupr = average_precision_score(true_binarized, pred_probs, average='macro')\n",
        "precision = precision_score(test_labels, pred_labels, average='macro')\n",
        "recall = recall_score(test_labels, pred_labels, average='macro')\n",
        "f1 = f1_score(test_labels, pred_labels, average='macro')\n",
        "cm = confusion_matrix(test_labels, pred_labels)\n",
        "report = classification_report(test_labels, pred_labels)\n",
        "\n",
        "# Print metrics\n",
        "print(f\"✅ Accuracy: {accuracy:.4f}\")\n",
        "print(f\"✅ ROC AUC Score: {roc_auc:.4f}\")\n",
        "print(f\"✅ AUPR Score: {aupr:.4f}\")\n",
        "print(f\"✅ Precision: {precision:.4f}\")\n",
        "print(f\"✅ Recall: {recall:.4f}\")\n",
        "print(f\"✅ F1 Score: {f1:.4f}\")\n",
        "print(\"\\n✅ Confusion Matrix:\")\n",
        "print(cm)\n",
        "print(\"\\n✅ Classification Report:\")\n",
        "print(report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbb697c7-1d90-42bc-b746-7188b3299703",
        "id": "HrZUidPn6vf9"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Accuracy: 0.9771\n",
            "✅ ROC AUC Score: 0.9986\n",
            "✅ AUPR Score: 0.9965\n",
            "✅ Precision: 0.9772\n",
            "✅ Recall: 0.9771\n",
            "✅ F1 Score: 0.9771\n",
            "\n",
            "✅ Confusion Matrix:\n",
            "[[239   0   1   0]\n",
            " [  0 228  11   1]\n",
            " [  0   7 233   0]\n",
            " [  0   2   0 238]]\n",
            "\n",
            "✅ Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       240\n",
            "           1       0.96      0.95      0.96       240\n",
            "           2       0.95      0.97      0.96       240\n",
            "           3       1.00      0.99      0.99       240\n",
            "\n",
            "    accuracy                           0.98       960\n",
            "   macro avg       0.98      0.98      0.98       960\n",
            "weighted avg       0.98      0.98      0.98       960\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4tGqpY_v7OtL"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Vt0XL_e27Pg-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "60 40"
      ],
      "metadata": {
        "id": "kPnof2DW7Sur"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "\n",
        "# Base original data directory\n",
        "base_dir = \"/content/colon_dataset\"\n",
        "train_dir = os.path.join(base_dir, \"train\")\n",
        "val_dir = os.path.join(base_dir, \"val\")\n",
        "test_dir = os.path.join(base_dir, \"test\")\n",
        "\n",
        "# New root for fixed structure\n",
        "fixed_base_dir = \"/content/colon_data_fixed\"\n",
        "combined_dir = os.path.join(fixed_base_dir, \"all_data\")\n",
        "new_train_dir = os.path.join(fixed_base_dir, \"train\")\n",
        "new_test_dir = os.path.join(fixed_base_dir, \"test\")\n",
        "new_val_dir = os.path.join(fixed_base_dir, \"val\")\n",
        "\n",
        "# Create fixed base directory\n",
        "os.makedirs(combined_dir, exist_ok=True)\n",
        "\n",
        "# Combine train + test data into one \"all_data\" folder\n",
        "for source_folder in [train_dir, test_dir]:\n",
        "    for class_name in os.listdir(source_folder):\n",
        "        src_path = os.path.join(source_folder, class_name)\n",
        "        dst_path = os.path.join(combined_dir, class_name)\n",
        "        os.makedirs(dst_path, exist_ok=True)\n",
        "        for file in os.listdir(src_path):\n",
        "            shutil.copy(os.path.join(src_path, file), os.path.join(dst_path, file))\n",
        "\n",
        "# Function to split into 80% train / 20% test\n",
        "def split_data(source_dir, train_dir, test_dir, ratio=0.6):\n",
        "    for class_name in os.listdir(source_dir):\n",
        "        class_path = os.path.join(source_dir, class_name)\n",
        "        files = os.listdir(class_path)\n",
        "        random.shuffle(files)\n",
        "        split_idx = int(len(files) * ratio)\n",
        "\n",
        "        train_files = files[:split_idx]\n",
        "        test_files = files[split_idx:]\n",
        "\n",
        "        for out_dir, file_list in [(train_dir, train_files), (test_dir, test_files)]:\n",
        "            class_out = os.path.join(out_dir, class_name)\n",
        "            os.makedirs(class_out, exist_ok=True)\n",
        "            for f in file_list:\n",
        "                shutil.copy(os.path.join(class_path, f), os.path.join(class_out, f))\n",
        "\n",
        "# Apply the split\n",
        "split_data(combined_dir, new_train_dir, new_test_dir)\n",
        "\n",
        "# Copy val data unchanged\n",
        "shutil.copytree(val_dir, new_val_dir, dirs_exist_ok=True)\n",
        "\n",
        "print(\"✅ Split complete!\")\n",
        "print(\"Train path:\", new_train_dir)\n",
        "print(\"Test path:\", new_test_dir)\n",
        "print(\"Validation path:\", new_val_dir)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e6288c5-ce21-4f3d-a0f3-58040f6251f5",
        "id": "GfRCCTpC7QAV"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Split complete!\n",
            "Train path: /content/colon_data_fixed/train\n",
            "Test path: /content/colon_data_fixed/test\n",
            "Validation path: /content/colon_data_fixed/val\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Original train folder\n",
        "original_train_dir = '/content/colon_dataset/train'\n",
        "train_split_dir = '/content/colon_dataset/train_split'\n",
        "test_split_dir = '/content/colon_dataset/test_split'\n",
        "\n",
        "# Make new directories\n",
        "os.makedirs(train_split_dir, exist_ok=True)\n",
        "os.makedirs(test_split_dir, exist_ok=True)\n",
        "\n",
        "for class_name in os.listdir(original_train_dir):\n",
        "    class_dir = os.path.join(original_train_dir, class_name)\n",
        "    if os.path.isdir(class_dir):\n",
        "        images = os.listdir(class_dir)\n",
        "        train_imgs, test_imgs = train_test_split(images, test_size=0.4, random_state=42)\n",
        "\n",
        "        os.makedirs(os.path.join(train_split_dir, class_name), exist_ok=True)\n",
        "        os.makedirs(os.path.join(test_split_dir, class_name), exist_ok=True)\n",
        "\n",
        "        # Move images\n",
        "        for img in train_imgs:\n",
        "            shutil.copy2(os.path.join(class_dir, img), os.path.join(train_split_dir, class_name, img))\n",
        "        for img in test_imgs:\n",
        "            shutil.copy2(os.path.join(class_dir, img), os.path.join(test_split_dir, class_name, img))\n",
        "\n",
        "print(\"✅ Train/Test split (60/40) completed.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e8934c6-2fec-40ec-db24-69560c5ae5bc",
        "id": "3LFI-8UF7QAV"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Train/Test split (60/40) completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = '/content/colon_dataset/train_split'\n",
        "test_dir = '/content/colon_dataset/test_split'\n",
        "val_dir = '/content/colon_dataset/val'\n",
        "\n",
        "# [Keep the rest of the code unchanged]\n"
      ],
      "metadata": {
        "id": "1zdIxgwj7QAV"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "\n",
        "img_size = (224, 224)\n",
        "batch_size = 32\n",
        "\n",
        "train_dir = '/content/colon_dataset/train_split'\n",
        "test_dir = '/content/colon_dataset/test_split'\n",
        "val_dir = '/content/colon_dataset/val'\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c56d9d8c-95c5-48ce-a94a-42fe615be3b4",
        "id": "GA7otCzD7QAV"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2880 images belonging to 4 classes.\n",
            "Found 2000 images belonging to 4 classes.\n",
            "Found 1280 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "img_size = (224, 224)\n",
        "batch_size = 32\n",
        "\n",
        "# Training and augmentation\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    '/content/colon_dataset/train_split',\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    '/content/colon_dataset/test_split',\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    '/content/colon_dataset/val',\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b123ad16-60d0-4efa-9e2c-37718af98422",
        "id": "Gup9iigd7QAW"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2880 images belonging to 4 classes.\n",
            "Found 1280 images belonging to 4 classes.\n",
            "Found 2000 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import DenseNet121\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dropout(0.5)(x)\n",
        "predictions = Dense(4, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Freeze base model\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "OvSkDu4r7QAW"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=10,\n",
        "    validation_data=val_generator\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b50c028-ad5e-4b08-a301-348704475455",
        "id": "biX55MJf7QAW"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - accuracy: 0.2724 - loss: 2.1404"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, average_precision_score, f1_score, precision_score, recall_score\n",
        "import numpy as np\n",
        "\n",
        "# Predict on test set\n",
        "y_true = test_generator.classes\n",
        "y_pred_probs = model.predict(test_generator)\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "# Basic metrics\n",
        "accuracy = np.mean(y_true == y_pred)\n",
        "f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "precision = precision_score(y_true, y_pred, average='weighted')\n",
        "recall = recall_score(y_true, y_pred, average='weighted')\n",
        "roc_auc = roc_auc_score(y_true, y_pred_probs, multi_class='ovr')\n",
        "aupr = average_precision_score(y_true, y_pred_probs, average='weighted')\n",
        "conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "report = classification_report(y_true, y_pred)\n",
        "\n",
        "# Print results\n",
        "print(f\"✅ Accuracy: {accuracy:.4f}\")\n",
        "print(f\"✅ ROC AUC Score: {roc_auc:.4f}\")\n",
        "print(f\"✅ AUPR Score: {aupr:.4f}\")\n",
        "print(f\"✅ Precision: {precision:.4f}\")\n",
        "print(f\"✅ Recall: {recall:.4f}\")\n",
        "print(f\"✅ F1 Score: {f1:.4f}\")\n",
        "print(f\"\\n✅ Confusion Matrix:\\n{conf_matrix}\")\n",
        "print(f\"\\n✅ Classification Report:\\n{report}\")\n"
      ],
      "metadata": {
        "id": "WnPmWu4z7QAW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler, label_binarize\n",
        "from sklearn.metrics import (accuracy_score, roc_auc_score, average_precision_score,\n",
        "                             precision_score, recall_score, f1_score, confusion_matrix,\n",
        "                             classification_report)\n",
        "from tensorflow.keras.applications import DenseNet121\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import GaussianNoise, Dropout\n",
        "from tensorflow.keras.applications.densenet import preprocess_input\n",
        "from tqdm import tqdm\n",
        "\n",
        "# -----------------------------------\n",
        "# 1. Load DenseNet121 with Regularization\n",
        "# -----------------------------------\n",
        "base_model = DenseNet121(weights='imagenet', include_top=False, pooling='avg', input_shape=(224, 224, 3))\n",
        "\n",
        "# Add Gaussian Noise and Dropout for regularization\n",
        "x = GaussianNoise(0.1)(base_model.output)\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "# Final feature extraction model\n",
        "feature_model = Model(inputs=base_model.input, outputs=x)\n",
        "\n",
        "# -----------------------------------\n",
        "# 2. Feature Extraction Function\n",
        "# -----------------------------------\n",
        "def extract_features(generator, model):\n",
        "    features, labels = [], []\n",
        "    for i in tqdm(range(len(generator))):\n",
        "        x_batch, y_batch = generator[i]\n",
        "        x_batch = preprocess_input(x_batch)\n",
        "        batch_features = model.predict(x_batch, verbose=0)\n",
        "        features.append(batch_features)\n",
        "        labels.append(y_batch)\n",
        "    return np.vstack(features), np.concatenate(labels)\n",
        "\n",
        "# -----------------------------------\n",
        "# 3. Extract Features from Train/Val/Test Sets\n",
        "# (Assumes `train_generator`, `val_generator`, and `test_generator` are already defined)\n",
        "# -----------------------------------\n",
        "train_features, train_labels = extract_features(train_generator, feature_model)\n",
        "val_features, val_labels = extract_features(val_generator, feature_model)\n",
        "test_features, test_labels = extract_features(test_generator, feature_model)\n",
        "\n"
      ],
      "metadata": {
        "id": "Q11BZLsq7QAW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components=0.95)  # Keep 95% variance\n",
        "train_features = pca.fit_transform(train_features)\n",
        "val_features = pca.transform(val_features)\n",
        "test_features = pca.transform(test_features)\n"
      ],
      "metadata": {
        "id": "zh4QdQyH7QAW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, roc_auc_score, average_precision_score,\n",
        "    precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
        ")\n",
        "from sklearn.preprocessing import label_binarize\n",
        "import numpy as np\n",
        "\n",
        "# Fix the label shape\n",
        "train_labels = np.argmax(train_labels, axis=1)\n",
        "test_labels = np.argmax(test_labels, axis=1)\n",
        "\n",
        "# Train SVM\n",
        "svm_clf = make_pipeline(StandardScaler(), SVC(kernel='rbf', probability=True, C=10, gamma='scale', random_state=42))\n",
        "svm_clf.fit(train_features, train_labels)\n",
        "\n",
        "# Predict\n",
        "pred_probs = svm_clf.predict_proba(test_features)\n",
        "pred_labels = np.argmax(pred_probs, axis=1)\n",
        "\n",
        "# Binarize for multi-class metrics\n",
        "n_classes = len(np.unique(test_labels))\n",
        "true_binarized = label_binarize(test_labels, classes=list(range(n_classes)))\n",
        "pred_binarized = label_binarize(pred_labels, classes=list(range(n_classes)))\n",
        "\n",
        "# Metrics\n",
        "accuracy = accuracy_score(test_labels, pred_labels)\n",
        "roc_auc = roc_auc_score(true_binarized, pred_probs, average='macro', multi_class='ovr')\n",
        "aupr = average_precision_score(true_binarized, pred_probs, average='macro')\n",
        "precision = precision_score(test_labels, pred_labels, average='macro')\n",
        "recall = recall_score(test_labels, pred_labels, average='macro')\n",
        "f1 = f1_score(test_labels, pred_labels, average='macro')\n",
        "cm = confusion_matrix(test_labels, pred_labels)\n",
        "report = classification_report(test_labels, pred_labels, target_names=test_generator.class_indices.keys())\n",
        "\n",
        "# Output\n",
        "print(f\"✅ Accuracy: {accuracy:.4f}\")\n",
        "print(f\"✅ ROC AUC Score: {roc_auc:.4f}\")\n",
        "print(f\"✅ AUPR Score: {aupr:.4f}\")\n",
        "print(f\"✅ Precision: {precision:.4f}\")\n",
        "print(f\"✅ Recall: {recall:.4f}\")\n",
        "print(f\"✅ F1 Score: {f1:.4f}\")\n",
        "print(\"\\n✅ Confusion Matrix:\")\n",
        "print(cm)\n",
        "print(\"\\n✅ Classification Report:\")\n",
        "print(report)\n"
      ],
      "metadata": {
        "id": "0rr2uXm77QAW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler, label_binarize\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, roc_auc_score, average_precision_score,\n",
        "    precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
        ")\n",
        "import numpy as np\n",
        "\n",
        "# Optional: scale features (important for some classifiers, less so for RF but keeps consistency)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(train_features)\n",
        "X_test_scaled = scaler.transform(test_features)\n",
        "\n",
        "# Train Random Forest\n",
        "rf_clf = RandomForestClassifier(n_estimators=200, max_depth=20, random_state=42, n_jobs=-1)\n",
        "rf_clf.fit(X_train_scaled, train_labels)\n",
        "\n",
        "# Predict\n",
        "pred_probs = rf_clf.predict_proba(X_test_scaled)\n",
        "pred_labels = np.argmax(pred_probs, axis=1)\n",
        "\n",
        "# Binarize for multi-class AUC and AUPR\n",
        "n_classes = len(np.unique(test_labels))\n",
        "true_binarized = label_binarize(test_labels, classes=list(range(n_classes)))\n",
        "pred_binarized = label_binarize(pred_labels, classes=list(range(n_classes)))\n",
        "\n",
        "# Evaluation\n",
        "accuracy = accuracy_score(test_labels, pred_labels)\n",
        "roc_auc = roc_auc_score(true_binarized, pred_probs, average='macro', multi_class='ovr')\n",
        "aupr = average_precision_score(true_binarized, pred_probs, average='macro')\n",
        "precision = precision_score(test_labels, pred_labels, average='macro')\n",
        "recall = recall_score(test_labels, pred_labels, average='macro')\n",
        "f1 = f1_score(test_labels, pred_labels, average='macro')\n",
        "cm = confusion_matrix(test_labels, pred_labels)\n",
        "report = classification_report(test_labels, pred_labels)\n",
        "\n",
        "# Output\n",
        "print(f\"✅ Accuracy: {accuracy:.4f}\")\n",
        "print(f\"✅ ROC AUC Score: {roc_auc:.4f}\")\n",
        "print(f\"✅ AUPR Score: {aupr:.4f}\")\n",
        "print(f\"✅ Precision: {precision:.4f}\")\n",
        "print(f\"✅ Recall: {recall:.4f}\")\n",
        "print(f\"✅ F1 Score: {f1:.4f}\")\n",
        "\n",
        "print(\"\\n✅ Confusion Matrix:\")\n",
        "print(cm)\n",
        "\n",
        "print(\"\\n✅ Classification Report:\")\n",
        "print(report)\n"
      ],
      "metadata": {
        "id": "NvSbQRMZ7QAX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.preprocessing import StandardScaler, label_binarize\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, roc_auc_score, average_precision_score,\n",
        "    precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
        ")\n",
        "import numpy as np\n",
        "\n",
        "# Scale features (helps even with XGBoost sometimes)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(train_features)\n",
        "X_test_scaled = scaler.transform(test_features)\n",
        "\n",
        "# Initialize XGBoost classifier\n",
        "xgb_clf = XGBClassifier(\n",
        "    n_estimators=200,\n",
        "    max_depth=8,\n",
        "    learning_rate=0.05,\n",
        "    objective='multi:softprob',\n",
        "    num_class=4,\n",
        "    use_label_encoder=False,\n",
        "    eval_metric='mlogloss',\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Train\n",
        "xgb_clf.fit(X_train_scaled, train_labels)\n",
        "\n",
        "# Predict probabilities and labels\n",
        "pred_probs = xgb_clf.predict_proba(X_test_scaled)\n",
        "pred_labels = np.argmax(pred_probs, axis=1)\n",
        "\n",
        "# Binarize for multi-class AUC and AUPR\n",
        "n_classes = len(np.unique(test_labels))\n",
        "true_binarized = label_binarize(test_labels, classes=list(range(n_classes)))\n",
        "pred_binarized = label_binarize(pred_labels, classes=list(range(n_classes)))\n",
        "\n",
        "# Evaluation metrics\n",
        "accuracy = accuracy_score(test_labels, pred_labels)\n",
        "roc_auc = roc_auc_score(true_binarized, pred_probs, average='macro', multi_class='ovr')\n",
        "aupr = average_precision_score(true_binarized, pred_probs, average='macro')\n",
        "precision = precision_score(test_labels, pred_labels, average='macro')\n",
        "recall = recall_score(test_labels, pred_labels, average='macro')\n",
        "f1 = f1_score(test_labels, pred_labels, average='macro')\n",
        "cm = confusion_matrix(test_labels, pred_labels)\n",
        "report = classification_report(test_labels, pred_labels)\n",
        "\n",
        "# Results\n",
        "print(f\"✅ Accuracy: {accuracy:.4f}\")\n",
        "print(f\"✅ ROC AUC Score: {roc_auc:.4f}\")\n",
        "print(f\"✅ AUPR Score: {aupr:.4f}\")\n",
        "print(f\"✅ Precision: {precision:.4f}\")\n",
        "print(f\"✅ Recall: {recall:.4f}\")\n",
        "print(f\"✅ F1 Score: {f1:.4f}\")\n",
        "\n",
        "print(\"\\n✅ Confusion Matrix:\")\n",
        "print(cm)\n",
        "\n",
        "print(\"\\n✅ Classification Report:\")\n",
        "print(report)\n"
      ],
      "metadata": {
        "id": "2E0-Khjs7QAX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.preprocessing import StandardScaler, label_binarize\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, roc_auc_score, average_precision_score,\n",
        "    precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
        ")\n",
        "import numpy as np\n",
        "\n",
        "# Scale features (very important for SVM)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(train_features)\n",
        "X_test_scaled = scaler.transform(test_features)\n",
        "\n",
        "# Define base models\n",
        "svm_clf = SVC(kernel='rbf', probability=True, C=2, gamma='scale', random_state=42)\n",
        "rf_clf = RandomForestClassifier(n_estimators=150, max_depth=12, random_state=42, n_jobs=-1)\n",
        "xgb_clf = XGBClassifier(\n",
        "    n_estimators=200,\n",
        "    max_depth=8,\n",
        "    learning_rate=0.05,\n",
        "    objective='multi:softprob',\n",
        "    num_class=4,\n",
        "    use_label_encoder=False,\n",
        "    eval_metric='mlogloss',\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Voting Classifier (soft voting based on probabilities)\n",
        "voting_clf = VotingClassifier(\n",
        "    estimators=[('svm', svm_clf), ('rf', rf_clf), ('xgb', xgb_clf)],\n",
        "    voting='soft',  # soft = use predicted probabilities\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Train ensemble\n",
        "voting_clf.fit(X_train_scaled, train_labels)\n",
        "\n",
        "# Predict\n",
        "pred_probs = voting_clf.predict_proba(X_test_scaled)\n",
        "pred_labels = np.argmax(pred_probs, axis=1)\n",
        "\n",
        "# Binarize for AUC/AUPR\n",
        "n_classes = len(np.unique(test_labels))\n",
        "true_binarized = label_binarize(test_labels, classes=list(range(n_classes)))\n",
        "pred_binarized = label_binarize(pred_labels, classes=list(range(n_classes)))\n",
        "\n",
        "# Metrics\n",
        "accuracy = accuracy_score(test_labels, pred_labels)\n",
        "roc_auc = roc_auc_score(true_binarized, pred_probs, average='macro', multi_class='ovr')\n",
        "aupr = average_precision_score(true_binarized, pred_probs, average='macro')\n",
        "precision = precision_score(test_labels, pred_labels, average='macro')\n",
        "recall = recall_score(test_labels, pred_labels, average='macro')\n",
        "f1 = f1_score(test_labels, pred_labels, average='macro')\n",
        "cm = confusion_matrix(test_labels, pred_labels)\n",
        "report = classification_report(test_labels, pred_labels)\n",
        "\n",
        "# Print results\n",
        "print(f\"✅ Accuracy: {accuracy:.4f}\")\n",
        "print(f\"✅ ROC AUC Score: {roc_auc:.4f}\")\n",
        "print(f\"✅ AUPR Score: {aupr:.4f}\")\n",
        "print(f\"✅ Precision: {precision:.4f}\")\n",
        "print(f\"✅ Recall: {recall:.4f}\")\n",
        "print(f\"✅ F1 Score: {f1:.4f}\")\n",
        "\n",
        "print(\"\\n✅ Confusion Matrix:\")\n",
        "print(cm)\n",
        "\n",
        "print(\"\\n✅ Classification Report:\")\n",
        "print(report)\n"
      ],
      "metadata": {
        "id": "QhM7wJem7QAX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler, label_binarize\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, roc_auc_score, average_precision_score,\n",
        "    precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
        ")\n",
        "import numpy as np\n",
        "\n",
        "# Feature scaling (essential for SVM)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(train_features)\n",
        "X_test_scaled = scaler.transform(test_features)\n",
        "\n",
        "\n",
        "# Meta learner\n",
        "meta_learner = LogisticRegression(max_iter=1000, multi_class='multinomial', solver='lbfgs')\n",
        "\n",
        "# Stacking classifier\n",
        "stacking_clf = StackingClassifier(\n",
        "    estimators=[\n",
        "        ('svm', svm_clf),\n",
        "        ('rf', rf_clf),\n",
        "        ('xgb', xgb_clf)\n",
        "    ],\n",
        "    final_estimator=meta_learner,\n",
        "    stack_method='predict_proba',  # Important for multiclass classification\n",
        "    cv=5,\n",
        "    n_jobs=-1,\n",
        "    passthrough=False\n",
        ")\n",
        "\n",
        "# Train ensemble\n",
        "stacking_clf.fit(X_train_scaled, train_labels)\n",
        "\n",
        "# Predict\n",
        "pred_probs = stacking_clf.predict_proba(X_test_scaled)\n",
        "pred_labels = np.argmax(pred_probs, axis=1)\n",
        "\n",
        "# Binarize for multiclass AUC/AUPR\n",
        "n_classes = len(np.unique(test_labels))\n",
        "true_binarized = label_binarize(test_labels, classes=list(range(n_classes)))\n",
        "pred_binarized = label_binarize(pred_labels, classes=list(range(n_classes)))\n",
        "\n",
        "# Evaluation\n",
        "accuracy = accuracy_score(test_labels, pred_labels)\n",
        "roc_auc = roc_auc_score(true_binarized, pred_probs, average='macro', multi_class='ovr')\n",
        "aupr = average_precision_score(true_binarized, pred_probs, average='macro')\n",
        "precision = precision_score(test_labels, pred_labels, average='macro')\n",
        "recall = recall_score(test_labels, pred_labels, average='macro')\n",
        "f1 = f1_score(test_labels, pred_labels, average='macro')\n",
        "cm = confusion_matrix(test_labels, pred_labels)\n",
        "report = classification_report(test_labels, pred_labels)\n",
        "\n",
        "# Print metrics\n",
        "print(f\"✅ Accuracy: {accuracy:.4f}\")\n",
        "print(f\"✅ ROC AUC Score: {roc_auc:.4f}\")\n",
        "print(f\"✅ AUPR Score: {aupr:.4f}\")\n",
        "print(f\"✅ Precision: {precision:.4f}\")\n",
        "print(f\"✅ Recall: {recall:.4f}\")\n",
        "print(f\"✅ F1 Score: {f1:.4f}\")\n",
        "print(\"\\n✅ Confusion Matrix:\")\n",
        "print(cm)\n",
        "print(\"\\n✅ Classification Report:\")\n",
        "print(report)\n"
      ],
      "metadata": {
        "id": "MZdCEeoZ7QAX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hWvuTkoS7grb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}